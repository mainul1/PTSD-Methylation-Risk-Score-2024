{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation and covariate adjustment. The process in this file is computationally expensive and was run on the cluster. This file adds 'Gender' and exposure variables as a covariate to remove sex specfic and exprosure related differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings imported from other notebook Settings.ipynb\n",
    "#%run Settings.ipynb\n",
    "from pyarrow import feather\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, datetime\n",
    "from makedirectory import make_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the program is running locally or cluster\n",
    "process = os.popen('hostname') # open process\n",
    "p_loc = process.read() \n",
    "p_loc = p_loc.strip('\\n')\n",
    "\n",
    "process.close() # close\n",
    "\n",
    "if p_loc == 'WS-IDRB-404B':\n",
    "    print(\"Running locally\")\n",
    "else:\n",
    "    print(\"Running on cluster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2021-07-12_10-28-46 \n",
    "# import pandas as pd\n",
    "if p_loc == 'WS-IDRB-404B':\n",
    "    beta = feather.read_feather(\"G:/PGC ML/Pre_Processed Data/2021-11-15_21-41-53/DNHS_GTP_MRS_ArmyS_Prismo_methylation.feather\")\n",
    "    pheno = pd.read_csv(\"G:/PGC ML/Pre_Processed Data/2021-11-15_21-41-53/DNHS_GTP_MRS_ArmyS_Prismo_Pheno.csv\")\n",
    "else:\n",
    "    beta = feather.read_feather(\"/home/a/ahwani/PGCML/DNHS_GTP_MRS_ArmyS_Prismo_methylation.feather\")\n",
    "    pheno = pd.read_csv(\"/home/a/ahwani/PGCML/DNHS_GTP_MRS_ArmyS_Prismo_Pheno.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert cpg names to index\n",
    "beta = beta.set_index(\"CpGs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count different categories\n",
    "pheno['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno['Ptsdpm'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno['Ptsdlife'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this phenotype file race column has strings like 1,5/2,5\n",
    "# So we need to remve the substring after , otherwise an error in ML mode\n",
    "pheno['Race'] = pheno['Race'].str.split(',').str[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if \",\" is still there\n",
    "pheno['Race'].str.contains(',').any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension\n",
    "beta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outpheno type file has some columns not needed in ML\n",
    "# Lets remove them\n",
    "# Basename we will remove later, because we need it\n",
    "# pheno = pheno.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count nas values in each column\n",
    "len(pheno) - pheno.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Covariate adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pheno.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# covariates to adjust for\n",
    "# We removed \"Neu\" because cell types may sum up to 1\n",
    "# may effect liear model. \n",
    "# added 'Gender' as a covariate including \"Childhood_Mt\", \"Traumanum\" \n",
    "covars = [\"Bcell\", \"Cd4T\", \"Cd8T\",\"Mono\", \"Nk\", \n",
    "          \"Smos\", \"Comp.2\", \"Comp.3\", \"Age\", \"Gender\",\n",
    "          \"Childhood_Mt\", \"Traumanum\"]\n",
    "cols = [\"Basename\", \"Study\"] + covars\n",
    "cols\n",
    "covar_df = pheno[cols]\n",
    "covar_df = covar_df.dropna(subset = covars[:-2]) # drop nas without childhood trauma and trauma num becase we'll impute them\n",
    "covar_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check na\n",
    "covar_df.isna().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "studies = covar_df[\"Study\"].unique().tolist()\n",
    "studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seprate data based on study\n",
    "pheno_ls = [covar_df[covar_df[\"Study\"] == x] for x in studies]\n",
    "\n",
    "# Now impute missing values in each cohort\n",
    "# using column mean\n",
    "pheno_ls = [x.fillna(x.mean()) for x in pheno_ls]\n",
    "[x.shape for x in pheno_ls]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# check for nas\n",
    "[x.isna().any().sum() for x in pheno_ls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = beta.T # tranpose to get cpgs as columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now separate methylation data\n",
    "meth_ls = [beta.loc[beta.index.isin(x[\"Basename\"])] for x in pheno_ls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x.shape for x in meth_ls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now impute missing values in each cohort\n",
    "# using column mean\n",
    "meth_ls = [x.fillna(x.mean()) for x in meth_ls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for nas\n",
    "[x.isna().any().sum() for x in meth_ls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine after imputation so that we can test it \n",
    "# without covariate adjustment in machine learning\n",
    "meth_data = pd.concat(meth_ls)\n",
    "meth_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if df has zero element\n",
    "meth_data.isin([0]).any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Convert beta to m values\n",
    "meth_data_m = np.log((meth_data/(1-meth_data)))\n",
    "meth_data_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meth_data[\"Index\"] = meth_data.index\n",
    "meth_data_m[\"Index\"] = meth_data_m.index\n",
    "meth_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make directory data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# feather.write_feather(meth_data, \"G:/PGC ML/Pre_Processed Data/2021-11-15_21-41-53/Imputed_DNHS_GTP_MRS_ArmyS_Prsm.feather\")\n",
    "# feather.write_feather(meth_data_m, \"G:/PGC ML/Pre_Processed Data/2021-11-15_21-41-53/Imputed_DNHS_GTP_MRS_ArmyS_Prsm_m_vals.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now convert individual cohorts beta to m values\n",
    "meth_ls_mvals = [np.log(x/(1-x)) for x in meth_ls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meth_ls_mvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check shape\n",
    "[x.shape for x in meth_ls_mvals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x.shape for x in pheno_ls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets do covariate adjustment\n",
    "# Do it for each cohort seprately\n",
    "test_betavals =  [x.iloc[0:50, 0:10] for x in meth_ls] # meth_ls #\n",
    "test_mvals = [x.iloc[0:50, 0:10] for x in meth_ls_mvals]\n",
    "covar = [x.iloc[0:50, 2:] for x in pheno_ls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print([x.shape for x in test_betavals])\n",
    "print([x.shape for x in covar])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([x.shape for x in test_mvals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjusted_data = {'DNHS':[], 'GTP':[], 'MRS':[],\n",
    "#                 'Armystarrs':[], 'Prismo':[]}\n",
    "from collections import defaultdict\n",
    "adjusted_data = defaultdict(list)\n",
    "adjusted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For covariate adjustment, a model is fit on m-values\n",
    "# And the m-value is subtracted from the residuals\n",
    "from sklearn.linear_model import LinearRegression\n",
    "names = [\"beta\", \"m\"]\n",
    "dfs = [test_betavals, test_mvals]\n",
    "for k in range(len(dfs)): # loop over beta and m values\n",
    "    for i in range(len(dfs[k])): # loop over individual cohorts in beta and m\n",
    "        print(\"Processing data \", i+1)\n",
    "        for j in dfs[k][i]:\n",
    "            lr = LinearRegression().fit(covar[i], dfs[k][i][j])\n",
    "            pred = lr.predict(covar[i])\n",
    "            residuals = round((dfs[k][i][j]-pred), 5)\n",
    "            print(residuals.values[0:5])\n",
    "            adjusted_data[names[k] + \"_\" + studies[i]].append((residuals.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_data[\"beta_DNHS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_data[\"m_DNHS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpg_names = test_betavals[0].columns # it will be same of all cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Samples names in each cohort\n",
    "sample_names = [x.index for x in test_betavals]\n",
    "sample_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all\n",
    "sample_names = [item for sublist in sample_names for item in sublist]\n",
    "sample_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cpg_names[0:5])\n",
    "print(sample_names[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_studies(ptrn, in_dict):\n",
    "    \"\"\"\n",
    "    Function to pull out beta and m values in cohorts\n",
    "    Parameters:\n",
    "    ptrn: Pattern to search\n",
    "    in_dict: input dictionary \n",
    "    \"\"\"\n",
    "    return(dict(filter(lambda item: ptrn in item[0], in_dict.items())))\n",
    "\n",
    "\n",
    "def add_column_names(col_names, in_dict,\n",
    "                     cohorts):\n",
    "    \"\"\"\n",
    "    Function to add column names to each cohort\n",
    "    Parameters:\n",
    "    col_names: column names (cpgs)\n",
    "    in_dict: input dictionary\n",
    "    cohorts: Names of cohorts\n",
    "    \"\"\"\n",
    "    return([pd.DataFrame.from_dict(dict(zip(col_names, in_dict[x])))\n",
    "         for x in cohorts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_studies = pull_studies(ptrn=\"beta\", in_dict=adjusted_data)\n",
    "beta_studies.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_studies = pull_studies(ptrn=\"m_\", in_dict=adjusted_data)\n",
    "m_studies.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_beta = add_column_names(col_names=cpg_names,\n",
    "                             in_dict=beta_studies,\n",
    "                             cohorts=beta_studies.keys())\n",
    "\n",
    "final_m = add_column_names(col_names=cpg_names,\n",
    "                             in_dict=m_studies,\n",
    "                             cohorts=m_studies.keys())\n",
    "# [pd.DataFrame.from_dict(dict(zip(cpg_names, adjusted_data[x])))\n",
    "#          for x in studies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now combine all cohorts for beta and m values\n",
    "final_beta_comb = pd.concat(final_beta)\n",
    "final_m_comb = pd.concat(final_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert m values back to beta values after covariate adjustment\n",
    "final_m_comb = 1/(1+(1/np.exp(final_m_comb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_beta_comb[\"Index\"] = sample_names\n",
    "final_m_comb[\"Index\"] =  sample_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_beta_comb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_m_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make directory data\n",
    "# d_dir = make_directory(\"G:/PGC ML/Covariate Adjusted/\")\n",
    "# d_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save \n",
    "# feather.write_feather(final_beta_comb, \"G:/PGC ML/Pre_Processed Data/2021-07-12_10-28-46/Imputed_Covariate_adjusted_Meth.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We converted the values back to beta values after linear regression \n",
    "# residuals on m values\n",
    "# feather.write_feather(final_comb, \"G:/PGC ML/Pre_Processed Data/2021-07-12_10-28-46/Imputed_Covariate_adjusted_Meth_on_mvals.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "if p_loc != 'WS-IDRB-404B':\n",
    "    d_dir = make_directory(\"/work/a/ahwani/PGCML/Covariate Adjusted/\")\n",
    "    feather.write_feather(final_beta_comb, os.path.join(d_dir, \"Imputed_Covariate_including_childhood_and_total_trauma_adjusted_Meth.feather\"))\n",
    "\n",
    "\n",
    "    # We converted the values back to beta values after linear regression \n",
    "    # residuals on m values\n",
    "    feather.write_feather(final_m_comb, os.path.join(d_dir, \"Imputed_Covariate_including_childhood_and_total_trauma_adjusted_Meth_on_mvals_wo_Neu.feather\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "c7f26a759f40ab9c37874e3bd456128bab360bcf3e0593c3619dfc03d39f5835"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
