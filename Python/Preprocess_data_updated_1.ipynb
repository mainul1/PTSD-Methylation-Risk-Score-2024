{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook is a part of PGC ML project, identifying methylation signatures to predict PTSD and create methylation risk scores. \n",
    "\n",
    "#### This first notebook contains code to pre-process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First load the settings file\n",
    "%run Settings.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read the data\n",
    "\n",
    "def read_data(fname, dirpath = None, sheet_name = 0):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to load the data\n",
    "    Parameters: \n",
    "    fname: file name including extension you want to read\n",
    "    dirpath: path to the directory containing file, None by default\n",
    "    sheet_name: Sheet name for reading excel sheets\n",
    "    output: data frame\n",
    "    \n",
    "    \"\"\"\n",
    "    if dirpath is None:\n",
    "        p = fname\n",
    "    else:\n",
    "        p = dirpath+fname\n",
    "    \n",
    "    if fname.endswith(\".feather\"):\n",
    "        f = feather.read_feather(p)\n",
    "    elif fname.endswith(\".csv\"):\n",
    "        f = pd.read_csv(p)\n",
    "    elif fname.endswith(\".xlsx\"):\n",
    "        f = pd.read_excel(p, sheet_name = sheet_name)\n",
    "        \n",
    "    return(f)\n",
    "\n",
    "\n",
    "def get_samples(df, cols):\n",
    "    \"\"\"\n",
    "    Function to subset data\n",
    "    Parameters:\n",
    "    df: data frame\n",
    "    cols: columns\n",
    "    \"\"\"\n",
    "    meth = df.loc[:, df.columns.str.contains('|'.join(cols))]\n",
    "    return(meth)\n",
    "\n",
    "def get_trauma_exposed(df, col):\n",
    "    \"\"\"\n",
    "    Function to get only trauman exposed samples\n",
    "    Parameters: \n",
    "    df: data frame\n",
    "    col: column name to filter the data frame\n",
    "    \"\"\"\n",
    "    return(df[df[col] != 0])\n",
    "\n",
    "\n",
    "def remove_duplicates(df, col):\n",
    "    \"\"\"\n",
    "    Function to get only trauman exposed samples\n",
    "    Parameters: \n",
    "    df: data frame\n",
    "    col: column name that contain duplicate ids\n",
    "    \"\"\"\n",
    "    return(df.drop_duplicates(subset= col))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DNHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DNHS\n",
    "dnhs_path = \"G:/DNHS 2nd Batch/DNHS2ndBatachAnalysis/data/\"\n",
    "dnhs = read_data(fname=\"DNHS_Noob_QCd_ComBAT_adj_Batch1&2.feather\", dirpath = dnhs_path)\n",
    "dnhs_pheno = read_data(fname = \"pheno_PCs_QC_with_smoking_scores.csv\", dirpath=dnhs_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check shape\n",
    "print(\"DNHS beta shape :\", dnhs.shape)\n",
    "print(\"DNHS Pheno shape :\", dnhs_pheno.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# we will try to get max sample size of unique participants\n",
    "# As we have some nas values, we will first drop those duplicates\n",
    "# that have missing values in any columns\n",
    "# cols_wd_miss = dnhs_pheno.columns[dnhs_pheno.isnull().any()].tolist()\n",
    "# dnhs_pheno_unq = dnhs_pheno[~dnhs_pheno['RESP'].duplicated(keep=False) | \n",
    "#                             dnhs_pheno[cols_wd_miss].notnull().any(axis=1)]\n",
    "# # dnhs_pheno_comp = dnhs_pheno.dropna()\n",
    "# dnhs_pheno_unq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now get the trauma exposed only\n",
    "dnhs_pheno = get_trauma_exposed(df =  dnhs_pheno,\n",
    "                                col = 'TraumaNum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trauma number should be > 0\n",
    "dnhs_pheno['TraumaNum'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need only the unique resp ids\n",
    "print(\"No of unique ppts :\", len(dnhs_pheno['RESP'].unique()))\n",
    "dnhs_pheno = remove_duplicates(df = dnhs_pheno,\n",
    "                               col = \"RESP\")\n",
    "len(dnhs_pheno['RESP'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnhs.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now get the samples in phenotype file\n",
    "# It will have cpgs and other sample columns\n",
    "dnhs_cols = ['rowname']+ dnhs_pheno['X'].tolist() # cpgs and samples\n",
    "dnhs = get_samples(df = dnhs, cols = dnhs_cols)\n",
    "dnhs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnhs_pheno.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GTP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load GTP\n",
    "gtp = read_data(fname=\"G:/GTP Data/QCd Data/GTP_Noob_QCd_Combat_adj.feather\")\n",
    "gtp_pheno = read_data(fname=\"G:/GTP Data/QCd Data/Pheno_662_samps_With_smoking_scores.csv\")\n",
    "gtp_more_pheno = read_data(fname = \"G:/GTP Data/QCd Data/Agaz_ML_Pheno.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gtp_pheno_old = read_data(fname=\"G:/GTP Data/QCd Data/Pheno_662_samps.csv\")\n",
    "# gtp_pheno_old['BaseName'].str.contains('|'.join(gtp_pheno['BaseName'].to_list())).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check shape\n",
    "print(\"GTP beta shape :\", gtp.shape)\n",
    "print(\"GTP Pheno shape :\", gtp_pheno.shape)\n",
    "print(\"GTP more pheno :\", gtp_more_pheno.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if all are trauma exposed\n",
    "gtp_pheno[gtp_pheno['tei_total_types_experienced_somewitness'] == 0].shape\n",
    "# gtp_pheno[gtp_pheno['TEI_TOTAL_TYPES_Experienced_somewitness'] == 0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only trauma exposed\n",
    "gtp_pheno = get_trauma_exposed(df = gtp_pheno,\n",
    "                              col = 'tei_total_types_experienced_somewitness')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtp_pheno['tei_total_types_experienced_somewitness'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtp_pheno.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtp_pheno.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now merge two gtp phenotype files\n",
    "gtp_pheno_comb = pd.merge(gtp_pheno, gtp_more_pheno,\n",
    "                         left_on= 'BaseName', \n",
    "                          right_on='EPIC_795', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtp_pheno_comb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtp_pheno_comb.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now get the methylation samples that are in phenotype file\n",
    "gtp_cols = [\"rowname\"] + gtp_pheno_comb[\"BaseName\"].tolist()\n",
    "gtp = get_samples(df = gtp, cols=gtp_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MRS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load MRS\n",
    "mrs = read_data(fname=\"G:/PGC ML/MRS/MRS_noob_qcd_crossReactiveProbesRemoved_combat_CP_wcovar_age_ptsd_allPreAsControls.feather\")\n",
    "mrs_pheno = read_data(fname=\"G:/PGC ML/MRS/MRS_Pheno_With_smoking_scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the rows \n",
    "mrs_pheno = mrs_pheno.sort_values(by =[\"studyid\", \"visit\"],\n",
    "                                ascending=True, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrs_pheno = get_trauma_exposed(df = mrs_pheno,\n",
    "                              col = 'LECCUM_Stringent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrs_pheno['LECCUM_Stringent'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many have two time points\n",
    "mrs_pheno.groupby([\"studyid\"]).size().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Childhoot trauma is recorded on the first visit, so copy that\n",
    "# information for the second visit\n",
    "mrs_pheno[\"CTQ_TOTAL\"] = mrs_pheno.groupby([\"studyid\"])[\"CTQ_TOTAL\"].ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrs_pheno[[\"studyid\", \"visit\", \"CTQ_TOTAL\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check shape\n",
    "print(\"MRS beta shape :\", mrs.shape)\n",
    "print(\"MRS Pheno shape :\", mrs_pheno.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As MRS has pre and post, we will use only one sample\n",
    "mrs_pheno_post = mrs_pheno.loc[mrs_pheno[\"ID\"].str.contains('POST')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrs_pheno_post['Group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now get methylation samples that are in pheno\n",
    "mrs_cols = [\"V1\"] + mrs_pheno_post[\"BaseName\"].tolist()\n",
    "mrs_post = get_samples(df = mrs, cols=mrs_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrs_post\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ArmySTARRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "army_path = \"G:/PGC ML/ArmySTARRS/\"\n",
    "army_pheno = read_data(fname=\"armystarrs_Pheno_ML_updated.csv\", dirpath=army_path)\n",
    "army_meth = read_data(fname=\"Starrs_noob_qcd_crossReactiveProbesRemoved_combat_CP_wcovar_age2TP_ptsd_allPreAsControls.feather\",\n",
    "                     dirpath=army_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Armystarrs beta shape :\", army_meth.shape)\n",
    "print(\"Armystarrs Pheno shape :\", army_pheno.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples for two visits\n",
    "army_pheno[\"visit\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In armystarrs we have different trauma variables\n",
    "# lets conside either non-deployment related trauma or \n",
    "# deployment related trauma\n",
    "army_pheno[\"trauma_exposed_critA\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets keep only trauma exposed\n",
    "army_pheno = get_trauma_exposed(df = army_pheno, \n",
    "                               col = 'trauma_exposed_critA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "army_pheno['trauma_exposed_critA'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get only visit 2\n",
    "army_v2_pheno = army_pheno[army_pheno['visit'] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "army_v2_pheno['visit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "army_v2_pheno[\"trauma_exposed_critA\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns that have all nas\n",
    "army_v2_pheno = army_v2_pheno.dropna(axis=1, how = 'all')\n",
    "army_v2_pheno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"No of unique ppts :\", len(army_v2_pheno['EWAS_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "army_v2_pheno.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now get methylation samples that are in pheno\n",
    "army_cols = [\"V1\"] + army_v2_pheno[\"BaseName\"].tolist()\n",
    "army_v2_meth = get_samples(df = army_meth, cols = army_cols)\n",
    "army_v2_meth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "army_v2_pheno.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRISMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prismo_path =\"G:/PGC ML/PRISMO/\"\n",
    "prismo_pheno = read_data(fname=\"prismo_Pheno_ML_updated.csv\", dirpath=prismo_path)\n",
    "prismo_meth = read_data(fname=\"Prismo_noob_qcd_crossReactiveProbesRemoved_combat_CP_wcovar_age_ptsd_allPreAsControls.feather\",\n",
    "                     dirpath=prismo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Prismo beta shape :\", prismo_meth.shape)\n",
    "print(\"Prismo Pheno shape :\", prismo_pheno.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prismo_pheno[\"visit\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prismo_pheno = get_trauma_exposed(df = prismo_pheno,\n",
    "                                 col = 'Pes_number')\n",
    "prismo_pheno.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prismo_v2_pheno = prismo_pheno[prismo_pheno[\"visit\"] == \"2_epic\"]\n",
    "prismo_v2_pheno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prismo_v2_pheno.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"No of unique ppts :\", len(prismo_v2_pheno['EWAS_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prismo_v2_pheno.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prismo_meth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prismo_cols = [\"V1\"] + prismo_v2_pheno[\"BaseName\"].tolist()\n",
    "prismo_v2_meth = get_samples(df = prismo_meth, cols = prismo_cols)\n",
    "prismo_v2_meth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prismo_v2_pheno.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just a thought ----------------\n",
    "# in DNHS we have Remitted samples as well\n",
    "# So when we use ptsdpm, we need to remove those remitted ones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnhs_pheno.iloc[:5, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtp.iloc[:5, :5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now combine all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of dfs \n",
    "all_meth_dfs = [dnhs, gtp, mrs_post, army_v2_meth, prismo_v2_meth]\n",
    "\n",
    "# rename the first column\n",
    "all_meth_dfs = [x.rename(columns = {x.columns[0]: 'CpGs'}) \n",
    " for x in all_meth_dfs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x.iloc[:5, :5] for x in all_meth_dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all methylation data \n",
    "from functools import reduce\n",
    "dfs_merged = reduce(lambda left, right: pd.merge(left, right,\n",
    "                                                 on = \"CpGs\",\n",
    "                                                how='inner'), all_meth_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfs_merged['CpGs'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_merged.iloc[:5, :5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We also need to combine the phenotypes, but before we do that we need to get the common variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnhs_pheno.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtp_pheno_comb.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrs_pheno_post.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "army_v2_pheno.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prismo_v2_pheno.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raname the first columns\n",
    "# DNHS\n",
    "dnhs_pheno = dnhs_pheno.rename(columns={'X':'BaseName', 'race6cat':'Race',\n",
    "                          'childhood_cum_trauma': 'Childhood_MT',\n",
    "                           'life_worst_intrusion': 'Intrusion',\n",
    "                           'life_worst_avoidance': 'Avoidance',\n",
    "                           'life_worst_hyperarousal': 'Hyperarousal',\n",
    "                           'phq9sum': 'MDD',\n",
    "                           'gad7sum': 'GAD',\n",
    "                           'Life_PTS_severity': 'PTS_severity'\n",
    "                          })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GTP\n",
    "gtp_pheno_comb = gtp_pheno_comb.rename(columns={'Unnamed: 0':'BaseName',\n",
    "                               'mergedcapsandpsswinthin30days':'PTSDpm', \n",
    "                               'Life_PTSD_01': 'PTSDLife',\n",
    "                               'age_x': 'Age',\n",
    "                               'tei_total_types_experienced_somewitness':'TraumaNum',\n",
    "                              'caps_life_freqplusintens_combined': 'PTS_severity',\n",
    "                               'PSS_Intrusive': 'Intrusion',\n",
    "                               'PSS_avoidnumb': 'Avoidance',\n",
    "                               'PSS_hyperarousal': 'Hyperarousal',\n",
    "                               'BDItotalscore': 'MDD',\n",
    "                               'CTQTOT': 'Childhood_MT',\n",
    "                               'pc1': 'Comp.1',\n",
    "                               'pc2': 'Comp.2',\n",
    "                               'pc3': 'Comp.3',\n",
    "                               \n",
    "                              })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MRS\n",
    "mrs_pheno_post = mrs_pheno_post.rename(columns={'ba_race': 'race',\n",
    "                               'CAPSF1I2s': 'PTSDpm',\n",
    "                               'Lifetime.PTSD' : 'PTSDLife',\n",
    "                               'LECCUM_Stringent': 'TraumaNum',\n",
    "                               'CAPStots': 'PTS_severity',\n",
    "                               'CAPSBs': 'Intrusion',\n",
    "                               'CAPSCs': 'Avoidance',\n",
    "                               'CAPSDs': 'Hyperarousal',\n",
    "                               'BDI2_SUM': 'MDD',\n",
    "                               'BAI_mod_sev': 'GAD',\n",
    "                               'CTQ_TOTAL' : 'Childhood_MT',\n",
    "                               'Sex': 'Gender'\n",
    "                              })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raname the first columns\n",
    "# ArmyStarrs\n",
    "army_v2_pheno = army_v2_pheno.rename(columns={'race':'Race',\n",
    "                        'CURRENT_PTSD': \"PTSDpm\",\n",
    "                        'LIFETIME_PTSD': 'PTSDLife',\n",
    "                        'MaltreatmentGlobal': 'Childhood_MT',\n",
    "                        'trauma_exposed_critA': 'TraumaNum',\n",
    "                        'pcl17_b_5q': 'Intrusion',\n",
    "                        'pcl17_c_7q': 'Avoidance',\n",
    "                        'pcl17_d_5q': 'Hyperarousal',\n",
    "                        'PCL17_t23': 'PTS_severity',\n",
    "                        'CD8T.EPICnoob': 'CD8T',\n",
    "                        'CD4T.EPICnoob': 'CD4T',\n",
    "                        'NK.EPICnoob': 'NK',\n",
    "                        'Bcell.EPICnoob': 'Bcell',\n",
    "                        'Mono.EPICnoob': 'Mono',\n",
    "                        'Neu.EPICnoob': 'Neu'\n",
    "                          })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prismo\n",
    "prismo_v2_pheno = prismo_v2_pheno.rename(columns={'ancestry':'Race',\n",
    "                          'CURRENT_PTSD': \"PTSDpm\",\n",
    "                          'LIFETIME_PTSD': 'PTSDLife',\n",
    "                          'ETItot': 'Childhood_MT',\n",
    "                          'Pes_number': 'TraumaNum',\n",
    "                          'REEXPERIENCE': 'Intrusion',\n",
    "                          'AVOID': 'Avoidance',\n",
    "                          'HYPERAROUSAL': 'Hyperarousal',\n",
    "                          'TOTAL_SCORE': 'PTS_severity',\n",
    "                          'CD8T.Epic': 'CD8T',\n",
    "                          'CD4T.Epic': 'CD4T',\n",
    "                          'NK.Epic': 'NK',\n",
    "                          'Bcell.Epic': 'Bcell',\n",
    "                          'Mono.Epic': 'Mono',\n",
    "                          'Neu.Epic': 'Neu',\n",
    "                          'gender': 'Gender'\n",
    "                          })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnhs_pheno.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtp_pheno_comb.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For mrs, both Pcs from gwas and methylation data are available\n",
    "# Comp.1, Comp.2, Comp.3 are methylation\n",
    "mrs_pheno_post.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "army_v2_pheno.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prismo_v2_pheno.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have two age columns, lets drop one\n",
    "mrs_pheno_post.drop(columns=['Age'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x.drop(columns=['AGE'], inplace=True) for x in [army_v2_pheno, prismo_v2_pheno]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "need_cols = ['BaseName', 'Gender','race$', '^Age$', \n",
    "             'PTSDpm', 'PTSDLife', 'TraumaNum', \n",
    "             'CD8T$', 'CD4T$', 'NK$', 'Bcell$', 'Mono$',\n",
    "             'Neu$','PTS_severity', 'Childhood_MT',\n",
    "             'Intrusion', 'Avoidance', 'Hyperarousal', '^MDD$',\n",
    "            'Comp.2', 'Comp.3', 'Study$', 'SmoS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def get_cols(df, cols, case=None, title=None, sort=None):\n",
    "    \"\"\"\n",
    "    Function to get required columns\n",
    "    Parameters: \n",
    "    df: data frame\n",
    "    cols: columns that need to be fetched\n",
    "    case: If case should be ignored,  None by default\n",
    "    \n",
    "    Output: The dataframe with selected columns\n",
    "    \"\"\"\n",
    "    if case is True:\n",
    "        d = df.filter(regex=re.compile('|'.join(cols), re.IGNORECASE))\n",
    "    else:\n",
    "        d = df.filter(regex= re.compile('|'.join(cols)))\n",
    "        \n",
    "    if title is True:\n",
    "        d.columns = [i.title() for i in d.columns]\n",
    "        \n",
    "    if sort is True:\n",
    "        d = d.sort_index(axis=1)\n",
    "        \n",
    "    return(d)\n",
    "\n",
    "\n",
    "# get the frequency of elements\n",
    "def get_frequency(df, col):\n",
    "    return(df[col].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now get the required columns from all dfs\n",
    "\n",
    "all_phenos = [dnhs_pheno, gtp_pheno_comb, mrs_pheno_post,\n",
    "             army_v2_pheno, prismo_v2_pheno]\n",
    "phenos_sub = [get_cols(df = x, cols=need_cols, case=True,\n",
    "                      title=True, sort=True) for x in all_phenos]\n",
    "\n",
    "cohorts = [\"dnhs\", \"gtp\", \"mrs\", \"armystarrs\", \"prismo\"]\n",
    "\n",
    "phenos_sub = dict(zip(cohorts, phenos_sub)) # make a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenos_sub.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x.columns for x in phenos_sub.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get columns of each df\n",
    "dnhs_cols, gtp_cols, mrs_cols, army_cols, prismo_cols = [x.columns for x in phenos_sub.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnhs_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtp_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrs_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "army_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prismo_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if column names are matching\n",
    "(dnhs_cols == gtp_cols).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "def matching(l1, l2):\n",
    "    \"\"\"\n",
    "    Function to compare two lists and check the order\n",
    "    \n",
    "    Parameters:\n",
    "    l1: list 1\n",
    "    l2: list 2 \n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Total elements in l1 :\", len(l1))\n",
    "    print(\"Total elements in l2 :\", len(l2))\n",
    "    m = len([l for l in l1 if l in l2])\n",
    "    print(\"Elements matching between l1 and l2 :\", m)\n",
    "    if(len(l1) == len(l2)):\n",
    "        print(\"All in order :\", (l1 == l2).all())\n",
    "    else:\n",
    "        elm = list(set(l1).difference(l2))\n",
    "        print(elm)\n",
    "        l1 = [x for x in l1 if x not in elm]\n",
    "        print(l1)\n",
    "        print(\"All common elements in order :\", (l1 == l2).all())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching(l1 = dnhs_cols, l2 = gtp_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching(l1 = dnhs_cols, l2 = mrs_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching(l1 = dnhs_cols, l2 = army_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching(l1 = dnhs_cols, l2 = prismo_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common in all\n",
    "list(set(dnhs_cols) & set(mrs_cols) & set(army_cols) & set(prismo_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x.iloc[:5, :5] for x in phenos_sub.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenos_sub['gtp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to int\n",
    "gtp_p_sub = phenos_sub['gtp'].astype({\"Traumanum\":'int',\n",
    "                             })\n",
    "get_frequency(df=gtp_p_sub, col='Ptsdlife')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nas in ptsd life\n",
    "gtp_p_sub['Ptsdlife'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenos_sub['dnhs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of males and females\n",
    "[get_frequency(df = x, col='Gender') for x in phenos_sub.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_elements(df, col, new_elements, verbose = None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to replace the elements in a column, e.g female:2, male:1 \n",
    "    Parameters:\n",
    "    df: data frame in which you want to replace\n",
    "    col: name of the column in which you want to replace the elements\n",
    "    new_elements: new elements to replace with \n",
    "    verbose: Print some information, default None \n",
    "    \n",
    "    \"\"\"\n",
    "    df = df.copy(deep = True)\n",
    "    x = df[col].value_counts().index\n",
    "    if(len(x) != len(new_elements)):\n",
    "        raise ValueError(\"Elements to replace must have the same length as new elements\")\n",
    "    \n",
    "    d = {x[i]:new_elements[i] for i in range(len(new_elements))} # make dictionary\n",
    "    \n",
    "    if verbose is True:\n",
    "        print(\"Categories :\\n\", x)\n",
    "        print(\"Replacing :\\n\", d)\n",
    "    \n",
    "    df[col] = df[col].replace(d)\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace gender in DNHS\n",
    "# In original study, M = 2, F = 1\n",
    "# But here in ML we will replace it to make it uniform with other studies\n",
    "dnhs_final = replace_elements(df = phenos_sub['dnhs'], col='Gender', \n",
    "                       new_elements=[2,1], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before \n",
    "phenos_sub['dnhs']['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After replacing\n",
    "dnhs_final[\"Gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace gender in GTP\n",
    "gtp_final = replace_elements(df = phenos_sub['gtp'], col='Gender', \n",
    "                           new_elements=[2,1], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before \n",
    "phenos_sub['gtp']['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtp_final['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace race in GTP\n",
    "gtp_final = replace_elements(df = gtp_final, col = \"Race\",\n",
    "                              new_elements=[2,1], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtp_final[\"Race\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtp_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MRS\n",
    "phenos_sub['mrs']['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenos_sub['armystarrs']['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenos_sub['prismo']['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine phenotype data\n",
    "final = pd.concat([dnhs_final, gtp_final, phenos_sub['mrs'],\n",
    "                  phenos_sub['armystarrs'], phenos_sub['prismo']],\n",
    "                 sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check categories in final\n",
    "print(\"Gender:\\n\", final['Gender'].value_counts())\n",
    "print(\"PTSDpm:\\n\", final['Ptsdpm'].value_counts())\n",
    "print(\"PTSDlife:\\n\", final['Ptsdlife'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now check na in the combined data\n",
    "final.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now check if we have all the samples in pheno and methylation files\n",
    "dfs_merged.columns.str.contains('|'.join(final['Basename'].tolist())).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_all_match(first, second):\n",
    "    \"\"\"\n",
    "    Function to check if all the samples in methylation and phenotye match\n",
    "    Parameters: \n",
    "    first: Elements to search\n",
    "    second: Elements to search in\n",
    "    \"\"\"\n",
    "    all_match = first.str.contains('|'.join(second.tolist())).all()\n",
    "    num_match = first.str.contains('|'.join(second.tolist())).sum()\n",
    "    if not all_match:\n",
    "        raise ValueError('All are not matching')\n",
    "    elif all_match:\n",
    "        print(\"All samples match between pheno and methylation: \", num_match)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_all_match(first = final['Basename'], \n",
    "               second = dfs_merged.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now save the data\n",
    "# Create the directory and assign timestamp folder\n",
    "\n",
    "import os, datetime\n",
    "\n",
    "def make_directory(maindir = None, verbose = None):\n",
    "    \"\"\"\n",
    "    Function to create directory in you current working directory.\n",
    "    The function will have time stamp assigned\n",
    "    \n",
    "    Parameters: \n",
    "    dirname : name of main directory to hold newly created directories\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "#     os.chdir('..') # go one step back to the current dir\n",
    "    \n",
    "    if maindir is False or  maindir is True:\n",
    "        raise ValueError(\"dirname can't be True or False\")\n",
    "    \n",
    "    if maindir is None:\n",
    "        mydir = os.path.join(os.getcwd(),\n",
    "                     datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
    "        \n",
    "    elif maindir is not None:\n",
    "        mydir = os.path.join(os.getcwd(), maindir,\n",
    "                     datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
    "        \n",
    "    os.makedirs(mydir)\n",
    "        \n",
    "    if verbose:\n",
    "        print(\"Directory created:\", mydir)\n",
    "        \n",
    "    return(mydir)\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to directory and make folder\n",
    "os.chdir(\"G:/PGC ML/\")\n",
    "mydir = make_directory(maindir=\"Pre_Processed Data\",  verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Phenotype file\n",
    "final.to_csv(os.path.join(mydir, \"DNHS_GTP_MRS_ArmyS_Prismo_Pheno.csv\"),\n",
    "            index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_data(fname, df):\n",
    "    \"\"\"\n",
    "    Function to save the data\n",
    "    Parameters:\n",
    "    fname: file name\n",
    "    df: data frame\n",
    "    \"\"\"\n",
    "    if fname.endswith(\".csv\"):\n",
    "        df.to_csv(os.path.join(mydir, fname))\n",
    "    elif fname.endswith(\".feather\"):\n",
    "        feather.write_feather(df, os.path.join(mydir, fname))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save individual datasets\n",
    "pheno_f_names = [\"DNHS_UnqRESP_Pheno_final.csv\", \"GTP_Pheno_final.csv\",\n",
    "          \"MRS_POST_DEP_Pheno_final.csv\", \"ArmyStarrs_visit2_pheno.csv\",\n",
    "          \"Prismo_visit2_pheno.csv\"]\n",
    "\n",
    "individual_cohorts = [dnhs_final, gtp_final, phenos_sub['mrs'],\n",
    "                  phenos_sub['armystarrs'], phenos_sub['prismo']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pheno_f_names)):\n",
    "    save_data(fname=pheno_f_names[i], df = individual_cohorts[i])\n",
    "    print(pheno_f_names[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save individual methylation data \n",
    "meth_f_names = [\"DNHS_methylation_unq.feather\", \"GTP_methylation.feather\",\n",
    "               \"MRS_methylation_post.feather\",\n",
    "                \"ArmyStarrs_visit2_methylation.feather\",\n",
    "               \"Prismo_visit2_methylation.feather\"]\n",
    "for i in range(len(meth_f_names)):\n",
    "    save_data(fname=meth_f_names[i], df = all_meth_dfs[i])\n",
    "    print(meth_f_names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save combined methylation data\n",
    "feather.write_feather(dfs_merged, os.path.join(mydir, \"DNHS_GTP_MRS_ArmyS_Prismo_methylation.feather\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of columns that are matching \n",
    "# Without rowname column\n",
    "dfs_merged.columns.isin(final[\"Basename\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
