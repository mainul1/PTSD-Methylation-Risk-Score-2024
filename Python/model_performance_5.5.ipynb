{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model performance before and after feature selection. \n",
    "\n",
    "### Update in this version: \n",
    "#### 1. look at balancing the cases and controls in training and optimizing the feature weights. \n",
    "\n",
    "#### Weights are coefficient using elasticNet (L1 & L2 penalty), features were selected using kbest approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings imported from other notebook Settings.ipynb\n",
    "%run Settings.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from pyarrow import feather\n",
    "import nbimporter\n",
    "import joblib\n",
    "import os, datetime\n",
    "from makedirectory import make_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'qcd_data' not in globals(): # 2021-11-27_19-16-35, 2021-10-02_23-12-43, 2021-07-19_13-32-34\n",
    "    print(\"Loading data\")\n",
    "    qcd_data = joblib.load(\"G:/PGC ML/Combined Data/2022-03-30_15-07-11/DNHS_GTP_MRS_ArmyS_Prismo_combined.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[(k,qcd_data[k][0].iloc[:,0:4 ]) for k in qcd_data.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Male female count: 1 - M, 2 - F\n",
    "qcd_data['ptsdpm_wo_NonCpGs'][0]['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qcd_data['ptsdlife_wo_NonCpGs'][0]['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the models and features using kbest approach\n",
    "if 'models_after_fs' not in globals(): \n",
    "    print(\"Loading models\") # 2021-11-27_19-23-28 2021-10-03_06-04-14\n",
    "#     models_after_fs = joblib.load('G:/PGC ML/Trained Models/2021-10-03_06-04-14/RandomForest_after_fs.pkl')\n",
    "\n",
    "if 'accuracy' not in globals(): #2021-10-03_06-04-14\n",
    "    accuracy = joblib.load('G:/PGC ML/Trained Models/2022-08-31_22-07-47/logisticregressioncv_accuracy_after_fs.pkl')\n",
    "\n",
    "if 'important_fea' not in globals(): # 2021-11-28_14-05-29 2021-10-03_18-17-57\n",
    "    important_fea = joblib.load('G:/PGC ML/Feature Sets/2022-09-02_00-23-31/Important Feature sets.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we had features with methylation values stored previously\n",
    "# We actually need only the name of features so that we can pull the info\n",
    "# from QCd data. So let's pull the names and save them \n",
    "# Note => this version onwards we will save only feature names\n",
    "\n",
    "# --------------------------\n",
    "# It was needed in the earlier versions where I had both, feature names and data\n",
    "# important_fea_names = dict()\n",
    "# for k in important_fea.keys():\n",
    "#     f_index = np.arange(len(important_fea[k]))\n",
    "#     important_fea_names[k] = [(important_fea[k][indx][0], \n",
    "#                                important_fea[k][indx][1].columns) \n",
    "#                               for indx in f_index]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the modified important feature sets - save feature names\n",
    "# We dont need to run this code for the set where we saved only feature names\n",
    "# joblib.dump(important_fea_names, 'G:/PGC ML/Feature Sets/2022-03-31_09-55-46/Important Feature sets.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when we don't need\n",
    "# del important_fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features using kbest approach\n",
    "# Arrange features/accuracy in a data frame\n",
    "def arrange_ouput(acc, cols):\n",
    "    \"\"\"\n",
    "    Function to arrange the accuracy of the model\n",
    "    Parameters:\n",
    "    acc: accuracy\n",
    "    cols: column names\n",
    "    \"\"\"\n",
    "    acc = [(k, *t) for k, v in acc.items() for t in v]\n",
    "    acc_df = pd.DataFrame(acc, columns= cols)\n",
    "    return(acc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the rows with ms\n",
    "import pandas as pd\n",
    "accuracy_df = arrange_ouput(acc = accuracy, \n",
    "                           cols = ['Variable','features_num','accuracy'] )\n",
    "idx = accuracy_df.loc[accuracy_df.groupby('Variable')['accuracy'].idxmax()]\n",
    "idx = idx.sort_index()\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_ls = list(idx.itertuples(index=False))\n",
    "imp_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now get the index of import feature\n",
    "def get_index(imp, var):\n",
    "    print(var)\n",
    "    ind = [name.features_num for name in imp if name.Variable == var]\n",
    "    ind = ind[0]//10-1 # features in sets of 10, index at 0\n",
    "    return(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# var_names = [x.Variable for x in imp_ls]\n",
    "var_names = ['ptsdpm_wo_NonCpGs', 'ptsdpm_wo_NonCpGsXY']\n",
    "var_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_indx = [get_index(imp=imp_ls, var= x) for x in var_names]\n",
    "fea_indx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save cases and controls to use in the \n",
    "# \n",
    "# ptsd_group = pd.DataFrame(qcd_data['ptsdpm_wo_NonCpGs'][1], columns=['group'])\n",
    "# ptsd_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save group info\n",
    "# ptsd_group.to_csv(\"G:/PGC ML/Combined Data/2022-03-30_15-07-11/Ptsdpm_case_control_info.csv\",\n",
    "#                                    index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for ptsdpm\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from copy import deepcopy\n",
    "# Data with most significant feature sets\n",
    "# [][] indicates test data and labels\n",
    "\n",
    "def build_confusion_matrix(predictions, \n",
    "                           ytest, \n",
    "                           labels, \n",
    "                           title,\n",
    "                           plot_label = None,\n",
    "                           ax=None,\n",
    "                           xax=True,\n",
    "                           yax=True, \n",
    "                           colbar=True):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to build confusion matrix \n",
    "    \n",
    "    Input:\n",
    "    predictions: Prediction from the model\n",
    "    ytest: Test labels to match with predicted values\n",
    "    labels: Lablels for confusion matrix\n",
    "    title: Title for plot\n",
    "    plot_label: Labels for plot (eg, A, B), default None\n",
    "    ax: ax to plot on if new axes provided\n",
    "    xax: Option to turn off x axis label, default on\n",
    "    yax: Option to turn off y axis label, default on\n",
    "    colbar: Option to turn off colbar, default on\n",
    "    \n",
    "    Output: Confusion matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    \n",
    "    \n",
    "    # confusion matrix\n",
    "    cm = confusion_matrix(ytest, predictions, labels=labels)\n",
    "    print(cm)\n",
    "    \n",
    "    # plot confusion matrix\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                                  display_labels=labels)\n",
    "        \n",
    "    label_font = {'size':'14'}  # Adjust to fit\n",
    "    title_font = {'size':'15'}  # Adjust to fit\n",
    "\n",
    "    \n",
    "    # pass axes object\n",
    "    if ax is None and colbar: # no axes but colorbar by default\n",
    "        disp.plot()\n",
    "    elif ax is None and not colbar: # no axes and colorbar\n",
    "        disp.plot() # type: ignore\n",
    "        disp.im_.colorbar.remove()\n",
    "    elif ax is not None and colbar: # axes and colorbar\n",
    "        disp.plot(ax = ax)\n",
    "    else:\n",
    "        disp.plot(ax=ax)\n",
    "        disp.im_.colorbar.remove() # axes but no colorbar\n",
    "    \n",
    "    # set title\n",
    "    disp.ax_.set_title(title)\n",
    "    \n",
    "    # disp.ax_.set_ylabel(\"True label\", fontdict = label_font)\n",
    "\n",
    "    # disp.ax_.set_xlabel(\"Predicted label\", fontdict = label_font)\n",
    "\n",
    "    # Off xaxis label\n",
    "    if not xax:\n",
    "        disp.ax_.axes.get_xaxis().get_label().set_visible(False)\n",
    "     \n",
    "    # Off yaxis label\n",
    "    if not yax:\n",
    "        disp.ax_.axes.get_yaxis().get_label().set_visible(False)\n",
    "    \n",
    "    # set plot label\n",
    "    if plot_label is not None:\n",
    "        disp.ax_.text(-0.1, 1.15, plot_label, transform=ax.transAxes,\n",
    "                  fontsize=16, fontweight='bold', va='top', ha='right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train & test sets, build the model\n",
    "# and run predictions\n",
    "def run_model(top_fea, \n",
    "              qcd_data_ml, \n",
    "              clf, \n",
    "              key, \n",
    "              title,\n",
    "              plot_label=None,\n",
    "              ax=None,\n",
    "              xax=True,\n",
    "              yax=True,\n",
    "              colbar=True):\n",
    "    print(\"Traing data :.....\")\n",
    "    print(\"Training on \", key)\n",
    "    \n",
    "    # split into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(top_fea[key][0],\n",
    "                                                        qcd_data_ml[key][1], \n",
    "                                                        test_size = 0.25,\n",
    "                                                        random_state=0,\n",
    "                                                       stratify=qcd_data_ml[key][1])\n",
    "    \n",
    "     # Samples used in training\n",
    "    # train_s = X_train['Basename']\n",
    "    \n",
    "    # Remove sample identifier\n",
    "    X_train, X_test = [x.loc[:,~x.columns.str.contains(\"Basename\")] \n",
    "                       for x in [X_train, X_test]]\n",
    "    \n",
    "    # Testing small set\n",
    "#     X_train = X_train.iloc[:, :100]\n",
    "#     X_test = X_test.iloc[:, :100]\n",
    "\n",
    "    print(\"Train data shape: \", X_train.shape)\n",
    "    print(\"Test data shape: \", X_test.shape)\n",
    "    \n",
    "    # train and predict\n",
    "    clf_n = deepcopy(clf)\n",
    "    clf_n.fit(X_train, y_train)\n",
    "    prediction = clf_n.predict(X_test)\n",
    "    \n",
    "    print('Classification accuracy on test data: {:.3f}\\n',\n",
    "    classification_report(y_test, prediction))\n",
    "\n",
    "    # function call to make confusion matrix\n",
    "    plot = build_confusion_matrix(predictions=prediction, \n",
    "                                  ytest=y_test, \n",
    "                                  labels=[0,1], \n",
    "                                  title = title, \n",
    "                                  plot_label=plot_label,\n",
    "                                  ax = ax,\n",
    "                                  xax = xax,\n",
    "                                  yax = yax,\n",
    "                                  colbar = colbar)\n",
    "    return clf_n\n",
    "#     return({\"classifier\":clf_n, \"plot\":plot})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance before feature selection and plot confusion matrix for the model with all the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest\n",
    "clf_rf = make_pipeline(MinMaxScaler(),\n",
    "                       BalancedRandomForestClassifier(n_estimators=100, \n",
    "                                                      random_state=42,\n",
    "                                                      n_jobs = -1))\n",
    "# Gradient boosting\n",
    "clf_gb = make_pipeline(MinMaxScaler(),\n",
    "                       GradientBoostingClassifier(loss='deviance', \n",
    "                                                  learning_rate=0.1,\n",
    "                                                  n_estimators=100, \n",
    "                                                  subsample=1.0,\n",
    "                                                  criterion='friedman_mse',\n",
    "                                                  random_state=42)\n",
    "                      )\n",
    "# Lasso\n",
    "clf_lso = make_pipeline(MinMaxScaler(),  \n",
    "                        LogisticRegression(solver=\"liblinear\", \n",
    "                                           penalty=\"l1\",\n",
    "                                           max_iter=500,\n",
    "                                           class_weight = \"balanced\")\n",
    "                       )\n",
    "\n",
    "# elasticNet \n",
    "clf_EN = make_pipeline(MinMaxScaler(),  \n",
    "                        LogisticRegression(solver=\"saga\",\n",
    "                                           penalty=\"elasticnet\",\n",
    "                                           C = .95,\n",
    "                                           l1_ratio=0.1,\n",
    "                                           max_iter=1000,\n",
    "                                           class_weight = \"balanced\")\n",
    "                      )\n",
    "\n",
    "# Elastic net with cross validation\n",
    "cs = [0.5, 1, 2, 4, 5, 8, 10, 15]\n",
    "l1_r = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "clf_EN_CV =  make_pipeline(MinMaxScaler(), \n",
    "                           LogisticRegressionCV(cv = 10,\n",
    "                                                Cs = cs,\n",
    "                                                solver=\"saga\",\n",
    "                                                penalty=\"elasticnet\",\n",
    "                                                l1_ratios=l1_r,\n",
    "                                                max_iter=2000,\n",
    "                                                class_weight = \"balanced\")\n",
    "                          )\n",
    "# Current ptsd\n",
    "# keys = 'ptsdpm'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running models before feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elastic net CV\n",
    "# Random forest\n",
    "# fig, (ax1, ax2) = plt.subplots(1, 2, dpi=300) # axes for two figures\n",
    "# fig.set_figheight(3.8)\n",
    "# fig.set_figwidth(8)\n",
    "\n",
    "# EN_CV = [run_model(top_fea = qcd_data, \n",
    "#                     qcd_data_ml = qcd_data,\n",
    "#                     clf = clf_EN_CV, \n",
    "#                     key = key, \n",
    "#                     title = \"Current PTSD (elastic net) \\nwithout nonCpG probes\",\n",
    "#                     ax=ax) for key, ax in zip(var_names, (ax1, ax2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, dpi=300) # axes for two figures\n",
    "fig.set_figheight(3.8)\n",
    "fig.set_figwidth(8)\n",
    "\n",
    "full_df_names = [\"without nonCpG probes\", \"without nonCpG and XY probes\"]\n",
    "\n",
    "\n",
    "rf1_all = [run_model(top_fea = qcd_data, \n",
    "                    qcd_data_ml = qcd_data,\n",
    "                    clf = clf_rf, \n",
    "                    key = key, \n",
    "                    title = \"Current PTSD (Random forest) \\n\" + nm,\n",
    "                    ax=ax,\n",
    "                    yax = yax,\n",
    "                    colbar = cb) \n",
    "           for key, ax, nm, yax, cb in zip(var_names, \n",
    "                                           (ax1, ax2),\n",
    "                                           full_df_names,\n",
    "                                          [True, False],\n",
    "                                          [False, True])]\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting\n",
    "# [run_model(top_fea = qcd_data, \n",
    "#           qcd_data_ml = qcd_data,\n",
    "#           clf = clf_gbb, key = key, \n",
    "#          title = \"current PTSD (Gradient Boost)\" + key) for key in var_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso\n",
    "# run_model(top_fea = qcd_data, \n",
    "#           qcd_data_ml = qcd_data,\n",
    "#           clf = clf_lso, key = \"ptsdpm_cov_adj\", \n",
    "#          title = \"current PTSD (Lasso)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elasticNet\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, dpi=300) # axes for two figures\n",
    "fig.set_figheight(3.8)\n",
    "fig.set_figwidth(8)\n",
    "\n",
    "EN_all = [run_model(top_fea = qcd_data, \n",
    "                    qcd_data_ml = qcd_data,\n",
    "                    clf = clf_EN, \n",
    "                    key = key, \n",
    "                    title = \"Current PTSD (elasticNet) \\n\" + nm,\n",
    "                    ax=ax) for key, ax, nm in zip(var_names, (ax1, ax2),\n",
    "                                                 full_df_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fea_indx = [fea_indx[1]] # get only covariate adjusted data index\n",
    "fea_indx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keys = list(important_fea.keys())\n",
    "# keys[0]\n",
    "qcd_data['ptsdpm_wo_NonCpGs'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance on top features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_indx[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over keys and important feature list at the same time\n",
    "# Display number of features in each\n",
    "[(k, important_fea[k][indx][0]) for k, indx in zip(var_names, fea_indx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dic of top features, add df and number of features\n",
    "# fea_indx = fea_indx[0]\n",
    "fea_ls = [important_fea[k][indx][1]\n",
    "          for k, indx in zip(var_names, fea_indx)]\n",
    "fea_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common features in three dfs used in training\n",
    "common_fea = set(fea_ls[0]) & set(fea_ls[1])\n",
    "print(\"# of common features:\", len(common_fea))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qcd_data['ptsdlife_wo_NonCpGs'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary of top features,\n",
    "# each with key and a tuple (important features and outcome labels)\n",
    "\n",
    "def get_top_features(df_name, f_index):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to create a dictionary of top features from qcd data and \n",
    "    important features.\n",
    "    Input: \n",
    "    df_name : names (keys) of qcd data\n",
    "    f_index: list of index of top features\n",
    "    \n",
    "    output: \n",
    "    dictionary of important features with outcome variable\n",
    "    \n",
    "    \"\"\"\n",
    "    top_f = dict()\n",
    "    for key, ind in zip(df_name, f_index):\n",
    "        print(\"Working on :{}, with imp feature index :{}\".format(key, ind))\n",
    "        get_features = important_fea[key][ind][1].copy()\n",
    "        x_df = qcd_data[key][0].copy() # copy qcd df with features\n",
    "        labels = qcd_data[key][1].copy() # outcome labels\n",
    "        top_f[key] = (x_df.loc[:, x_df.columns.str.contains('|'.join(get_features))],\n",
    "              labels)\n",
    "        \n",
    "    return top_f\n",
    "\n",
    "\n",
    "top_fea = get_top_features(df_name = var_names, \n",
    "                            f_index = fea_indx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if we got all the important features\n",
    "# matching top features should be all true\n",
    "[(top_fea[k][0].columns == important_fea[k][i][1]).all() \n",
    " for k, i in zip(top_fea.keys(), fea_indx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top features in the earlier version\n",
    "# top_fea = dict({k:(important_fea[k][indx][1], qcd_data[k][1]) for k, indx in zip(var_names, fea_indx)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(top_fea.keys())\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if ids are matching\n",
    "(qcd_data['ptsdpm_wo_NonCpGs'][0]['Basename'] == qcd_data['ptsdpm_wo_NonCpGsXY'][0]['Basename']).all() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Now save the data in csv so that we could use\n",
    "# it in the getting demographic characteristics\n",
    "current_ptsd = [pd.concat([qcd_data[k][0]['Basename'], \n",
    "                         top_fea[k][0]], axis=1) for k in top_fea.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[print(\"Dim of current ptsd dfs {}\".format(x.shape)) for x in current_ptsd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add outcome variable (current ptsd) to each df\n",
    "for i,val in enumerate(current_ptsd):\n",
    "    current_ptsd[i]['current_ptsd'] = top_fea[keys[i]][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check shape\n",
    "def print_shape(in_df):\n",
    "    print(\"Length:\", len(in_df))\n",
    "    print(\"Shape without nonCpGs :\", in_df[0].shape)\n",
    "    print(\"Shape without nonCpGsXY :\", in_df[1].shape)\n",
    "    in_df[0].iloc[:,0:5].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current PTSD details\n",
    "print_shape(current_ptsd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "import pandas as pd\n",
    "path = \"G:/PGC ML/Combined Data/2022-03-30_15-07-11/\"\n",
    "writer = pd.ExcelWriter(path + 'ElasticNet_Current_ptsd_important_features.xlsx', \n",
    "                        engine='xlsxwriter')\n",
    "\n",
    "\n",
    "current_ptsd[0].to_excel(writer, sheet_name=\"Without NonCpG Probes\",\n",
    "                         index=False)\n",
    "current_ptsd[1].to_excel(writer, sheet_name=\"Without NonCpGXY Probes\",\n",
    "                         index=False)\n",
    "\n",
    "# Close the Pandas Excel writer and output the Excel file.\n",
    "writer.save()\n",
    "\n",
    "# current_ptsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keys of lifetime ptsd\n",
    "ptsdlife_keys = [k for k in qcd_data.keys() if 'ptsdlife' in k]\n",
    "ptsdlife_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lifetime_ptsd = [qcd_data[k][0] for k in ptsdlife_keys]\n",
    "[x.shape for x in lifetime_ptsd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now get important features only\n",
    "lifetime_ptsd = [x.loc[:, x.columns.str.contains('|'.join(y))] \n",
    "                       for x,y in zip(lifetime_ptsd, fea_ls)]\n",
    "[x.shape for x in lifetime_ptsd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now add sample id and lifetime ptsd\n",
    "lifetime_ptsd = [pd.concat([qcd_data[k][0]['Basename'], y], axis=1) \n",
    "                 for k, y in zip(ptsdlife_keys, lifetime_ptsd)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x.shape for x in lifetime_ptsd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add outcome variable (lifetime ptsd) to each df\n",
    "for i,val in enumerate(lifetime_ptsd):\n",
    "    lifetime_ptsd[i]['lifetime_ptsd'] = qcd_data[ptsdlife_keys[i]][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current Lifetime PTSD details\n",
    "print_shape(lifetime_ptsd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change file name to save if needed\n",
    "writer_life = pd.ExcelWriter(path + 'ElasticNet_Lifetime_ptsd_important_features.xlsx', \n",
    "                        engine='xlsxwriter')\n",
    "\n",
    "\n",
    "lifetime_ptsd[0].to_excel(writer_life, sheet_name=\"Without NonCpG Probes\",\n",
    "                         index=False)\n",
    "lifetime_ptsd[1].to_excel(writer_life, sheet_name=\"Without NonCpGXY Probes\",\n",
    "                         index=False)\n",
    "\n",
    "writer_life.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_fea.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Random forest on top features\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, dpi=300) # axes for two figures\n",
    "fig.set_figheight(3.8)\n",
    "fig.set_figwidth(8)\n",
    "model_rf1 = run_model(top_fea = top_fea, \n",
    "                      qcd_data_ml = qcd_data,\n",
    "                      clf = clf_rf, \n",
    "                      key = 'ptsdpm_wo_NonCpGs', \n",
    "                      title = \"Current PTSD (Random forest)- \\nwithout NonCpG probes\",\n",
    "                      plot_label = \"A\",\n",
    "                      ax=ax1,\n",
    "                      colbar=False)\n",
    "# plt.colorbar().remove()\n",
    "\n",
    "model_rf2 = run_model(top_fea = top_fea, \n",
    "                      qcd_data_ml = qcd_data,\n",
    "                      clf = clf_rf, \n",
    "                      key = 'ptsdpm_wo_NonCpGsXY', \n",
    "                      title = \"Current PTSD (Random forest)-\\nwithout NonCpG and XY probes\",\n",
    "                      ax=ax2,\n",
    "                      yax = False)\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(168+55)/(168+55+60+24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, dpi=300) # axes for two figures\n",
    "fig.set_figheight(3.8)\n",
    "fig.set_figwidth(8)\n",
    "model_gb1 = run_model(top_fea = top_fea, \n",
    "                      qcd_data_ml = qcd_data,\n",
    "                      clf = clf_gb, \n",
    "                      key = 'ptsdpm_wo_NonCpGs', \n",
    "                      title = \"Current PTSD (Gradient Boost)- \\nwithout NonCpG probes\",\n",
    "                      plot_label = \"A\",\n",
    "                      ax=ax1,\n",
    "                      colbar=False)\n",
    "# plt.colorbar().remove()\n",
    "\n",
    "model_gb2 = run_model(top_fea = top_fea, \n",
    "                      qcd_data_ml = qcd_data,\n",
    "                      clf = clf_gb, \n",
    "                      key = 'ptsdpm_wo_NonCpGsXY', \n",
    "                      title = \"Current PTSD (Gradient Boost)-\\nwithout NonCpG and XY probes\",\n",
    "                      ax=ax2,\n",
    "                      yax = False)\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sn\n",
    "# import pandas as pd\n",
    "# def build_confusion_matrix_test(ax, fig_title):\n",
    "#     cm = np.array([[279,  49],\n",
    "#                    [ 18 , 161]])\n",
    "#     print(cm)\n",
    "    \n",
    "#     disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "#                                   display_labels=[0,1])\n",
    "        \n",
    "#     title_font = {'size':'13.5'}  # Adjust to fit\n",
    "    \n",
    "#     disp.plot(ax = ax, colorbar=False) # pass axis and colorbar here\n",
    "#     disp.ax_.set_title(fig_title, fontdict = title_font)\n",
    "\n",
    "#     disp.ax_.grid(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, (ax1, ax2) = plt.subplots(1, 2, dpi=200)\n",
    "# # fig.set_figheight(4)\n",
    "# # fig.set_figwidth(10)\n",
    "# build_confusion_matrix_test(ax=ax1, fig_title= \"Fig A\")\n",
    "# # build_confusion_matrix_test(ax=ax2, fig_title= \"Fig B\")\n",
    "# # plt.tight_layout()\n",
    "# # test_plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import inspect\n",
    "# lines = inspect.getsource(ConfusionMatrixDisplay)\n",
    "# print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get feature importance from the model \n",
    "# used above on top features\n",
    "def get_feature_importance(modl, coef = False):\n",
    "    if coef:\n",
    "        importance = modl.steps[1][1].coef_\n",
    "        importance = importance[0].tolist() # convert numpy to list\n",
    "    else:\n",
    "        importance = modl.steps[1][1].feature_importances_\n",
    "        \n",
    "    print(\"10 Feature importance: \\n\", importance[1:10])\n",
    "    print(\"Length: \\n\", len(importance))\n",
    "    return(importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "non_cpgs_imp_rf = get_feature_importance(modl = model_rf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "non_cpgsXY_imp_rf = get_feature_importance(modl = model_rf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_fea['ptsdpm_wo_NonCpGs'][0].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_fea['ptsdpm_wo_NonCpGsXY'][0].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creat dataframes of important features with score\n",
    "def make_df(fea_importance, top_features):\n",
    "    \"\"\"\n",
    "    Function to make data frame of important features\n",
    "    Input: \n",
    "    fea_importance: featur importance\n",
    "    top_features: top features df/ to feature names if not list\n",
    "    \"\"\"\n",
    "    if isinstance(fea_importance, list): # if input is list\n",
    "        print(\"list passed as input...\")\n",
    "        return [pd.DataFrame(x, top_features[k][0].columns) \n",
    "         for x, k in zip(fea_importance, top_features.keys())]\n",
    "    else:\n",
    "        return pd.DataFrame(fea_importance, top_features)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_dfs_rf = make_df(fea_importance=[non_cpgs_imp_rf, non_cpgsXY_imp_rf],\n",
    "                            top_features=top_fea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_dfs_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrange_df(df):\n",
    "    df.reset_index(inplace=True)\n",
    "    df.columns = ['Feature', \"Importance\"]\n",
    "    df.sort_values(by=['Importance'], inplace=True)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_dfs_rf = [arrange_df(df = x) for x in importance_dfs_rf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_dfs_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_dfs_rf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save feature importance in csv\n",
    "importance_dfs_rf[0].to_csv(\"G:/PGC ML/Combined Data/2022-03-30_15-07-11/Important_features_wo_non_CpGs_RF_selected_wd_EN.csv\",\n",
    "                                   index=False)\n",
    "\n",
    "importance_dfs_rf[1].to_csv(\"G:/PGC ML/Combined Data/2022-03-30_15-07-11/Important_features_wo_non_CpGsXY_RF_selected_wd_EN.csv\",\n",
    "                                   index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso ------------------\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, dpi=300) # axes for two figures\n",
    "fig.set_figheight(3.8)\n",
    "fig.set_figwidth(8)\n",
    "model_lasso1 = run_model(top_fea = top_fea, \n",
    "                         qcd_data_ml = qcd_data,\n",
    "                         clf = clf_lso, \n",
    "                         key = \"ptsdpm_wo_NonCpGs\", \n",
    "                         title = \"Current PTSD (Lasso)-\\nwithout NonCpG probes\",\n",
    "                         plot_label='B',\n",
    "                         ax=ax1,\n",
    "                         colbar=False\n",
    "                        )\n",
    "\n",
    "\n",
    "model_lasso2 = run_model(top_fea = top_fea, \n",
    "                         qcd_data_ml = qcd_data,\n",
    "                         clf = clf_lso, \n",
    "                         key = \"ptsdpm_wo_NonCpGsXY\", \n",
    "                         title = \"Current PTSD (Lasso)-\\nwithout NonCpG and XY probes\",\n",
    "                         ax = ax2,\n",
    "                         yax = False)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importance - coefficients\n",
    "non_cpgs_imp_lasso, non_cpgsXY_imp_lasso = [get_feature_importance(modl=x, coef = True) \n",
    "                            for x in [model_lasso1, model_lasso2]]\n",
    "\n",
    "importance_dfs_lso = make_df(fea_importance=[non_cpgs_imp_lasso, non_cpgsXY_imp_lasso],\n",
    "                            top_features=top_fea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_dfs_lso = [arrange_df(df = x) for x in importance_dfs_lso]\n",
    "importance_dfs_lso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save feature importance in csv\n",
    "importance_dfs_lso[0].to_csv(\"G:/PGC ML/Combined Data/2022-03-30_15-07-11/Important_features_wo_non_CpGs_Lasso_selected_wd_EN.csv\",\n",
    "                                   index=False)\n",
    "\n",
    "importance_dfs_lso[1].to_csv(\"G:/PGC ML/Combined Data/2022-03-30_15-07-11/Important_features_wo_non_CpGsXY_Lasso_selected_wd_EN.csv\",\n",
    "                                   index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elesticNet -----------------------\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, dpi=200) # axes for two figures\n",
    "fig.set_figheight(3)\n",
    "fig.set_figwidth(6)\n",
    "model_elasticnet1 = run_model(top_fea = top_fea, \n",
    "                              qcd_data_ml = qcd_data,\n",
    "                              clf = clf_EN, \n",
    "                              key = \"ptsdpm_wo_NonCpGs\",\n",
    "                              title= \"Current PTSD (ElasticNet)-\\nwithout NonCpG probes\",\n",
    "                              plot_label='C',\n",
    "                              ax=ax1,\n",
    "                              colbar=False)\n",
    "\n",
    "model_elasticnet2 = run_model(top_fea = top_fea, \n",
    "                              qcd_data_ml = qcd_data,\n",
    "                              clf = clf_EN, \n",
    "                              key = \"ptsdpm_wo_NonCpGsXY\",\n",
    "                              title= \"Current PTSD (ElasticNet)-\\nwithout NonCpG and XY probes\",\n",
    "                              ax=ax2,\n",
    "                              yax=False)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ISTSS plot - confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1, 1, dpi=300) # axes for two figures\n",
    "fig.set_figheight(2)\n",
    "fig.set_figwidth(2.5)\n",
    "model_elasticnet_istss = run_model(top_fea = top_fea, \n",
    "                                   qcd_data_ml = qcd_data,\n",
    "                                   clf = clf_EN, \n",
    "                                   key = \"ptsdpm_wo_NonCpGsXY\",\n",
    "                                   title= \"Confusion matrix (ElasticNet)\",\n",
    "                                   ax = ax1)\n",
    "ax1.set_xticklabels([\"No PTSD\", \"PTSD\"])\n",
    "ax1.set_yticklabels([\"No PTSD\", \"PTSD\"])\n",
    "plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importance - coefficients\n",
    "non_cpgs_imp_en, non_cpgsXY_imp_en = [get_feature_importance(modl=x, coef = True) \n",
    "                            for x in [model_elasticnet1, model_elasticnet2]]\n",
    "\n",
    "importance_dfs_en = make_df(fea_importance=[non_cpgs_imp_en, non_cpgsXY_imp_en],\n",
    "                            top_features=top_fea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_dfs_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_dfs_en = [arrange_df(df = x) for x in importance_dfs_en]\n",
    "importance_dfs_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save feature importance in csv\n",
    "# First was using l1_ratio = 0.05\n",
    "# importance_dfs_en[0].to_csv(\"G:/PGC ML/Combined Data/2022-03-30_15-07-11/Important_features_wo_non_CpGs_EN_selected_wd_EN.csv\",\n",
    "#                                    index=False)\n",
    "\n",
    "# importance_dfs_en[1].to_csv(\"G:/PGC ML/Combined Data/2022-03-30_15-07-11/Important_features_wo_non_CpGsXY_EN_selected_wd_EN.csv\",\n",
    "#                                    index=False)\n",
    "\n",
    "\n",
    "importance_dfs_en[0].to_csv(\"G:/PGC ML/Combined Data/2022-03-30_15-07-11/Important_features_wo_non_CpGs_EN_selected_wd_EN_l1_r_0.1.csv\",\n",
    "                                   index=False)\n",
    "\n",
    "importance_dfs_en[1].to_csv(\"G:/PGC ML/Combined Data/2022-03-30_15-07-11/Important_features_wo_non_CpGsXY_EN_selected_wd_EN_l1_r_0.1.csv\",\n",
    "                                   index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Elastic net with cv\n",
    "# This was Cross validation to choose l1_ratio\n",
    "# It shows l1_ratio = 0.1 works better\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, dpi=300) # axes for two figures\n",
    "fig.set_figheight(3.8)\n",
    "fig.set_figwidth(8)\n",
    "EN_CV_1 = run_model(top_fea = top_fea, \n",
    "                              qcd_data_ml = qcd_data,\n",
    "                              clf = clf_EN_CV, \n",
    "                              key = \"ptsdpm_wo_NonCpGs\",\n",
    "                              title= \"Current PTSD (ElasticNet CV)-\\nwithout NonCpG probes\",\n",
    "                              plot_label='C',\n",
    "                              ax=ax1,\n",
    "                              colbar=False)\n",
    "\n",
    "EN_CV_2 = run_model(top_fea = top_fea, \n",
    "                              qcd_data_ml = qcd_data,\n",
    "                              clf = clf_EN_CV, \n",
    "                              key = \"ptsdpm_wo_NonCpGsXY\",\n",
    "                              title= \"Current PTSD (ElasticNet CV)-\\nwithout NonCpG and XY probes\",\n",
    "                              ax=ax2,\n",
    "                              yax=False)\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will save these models to use in future\n",
    "EN_CV_models = {'ptsdpm_wo_NonCpGs': EN_CV_1, \n",
    "                \"ptsdpm_wo_NonCpGsXY\": EN_CV_2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "joblib.dump(EN_CV_models, \"G:/PGC ML/Combined Data/2022-03-30_15-07-11/CV_EN_models.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EN_CV_1[1].intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EN_CV_1[1].l1_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EN_CV_1[1].Cs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EN_CV_1[1].scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As many features as zero coefficient, lets check model accuracy using features with non-zero coefficient only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# how many have non-zero coefficient\n",
    "en_fea_nonzero_imp = [(x.loc[x[\"Importance\"] != 0]) for x in importance_dfs_en]\n",
    "en_fea_nonzero_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many  have zero coeff\n",
    "[(x[\"Importance\"] == 0).sum() for x in importance_dfs_en]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(en_fea_nonzero_imp)):\n",
    "    print(i)\n",
    "en_fea_nonzero_imp[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nonzero_features(top, fea):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to get non zero coefficient features\n",
    "    \n",
    "    Input:\n",
    "    top: top features in dictionary\n",
    "    fea: nonzero coef features\n",
    "    \n",
    "    Output: \n",
    "    Dictionary of non zero coefficients\n",
    "    \"\"\"\n",
    "    rang = np.arange(len(fea))\n",
    "    nonzero =  dict()\n",
    "    for key, ind in zip(top.keys() , rang):\n",
    "        df = top[key][0].copy()\n",
    "        labels = top[key][1].copy()\n",
    "        features = fea[ind][\"Feature\"].tolist()\n",
    "        print(key)\n",
    "        nonzero[key] = (df.loc[:, df.columns.str.contains('|'.join(features))],\n",
    "                  labels)\n",
    "    return nonzero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_fea_nonzero = get_nonzero_features(top = top_fea,\n",
    "                                       fea = en_fea_nonzero_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if we got all the important features\n",
    "# matching top features should be all true\n",
    "[(top_fea_nonzero[k][0].columns.isin(en_fea_nonzero_imp[i][\"Feature\"].tolist())).all() \n",
    " for k, i in zip(top_fea.keys(), range(len(en_fea_nonzero_imp)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[top_fea_nonzero[k][0].shape for k in top_fea_nonzero.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now run the model for features with nonzero coefficients\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, dpi=300) # axes for two figures\n",
    "fig.set_figheight(3.8)\n",
    "fig.set_figwidth(8)\n",
    "model_en_nonzero1 = run_model(top_fea = top_fea_nonzero, \n",
    "                              qcd_data_ml = qcd_data,\n",
    "                              clf = clf_EN, \n",
    "                              key = \"ptsdpm_wo_NonCpGs\",\n",
    "                              title= \"Current PTSD (ElasticNet-nonzero)-\\nwithout NonCpG probes\",\n",
    "                              plot_label='C',\n",
    "                              ax=ax1,\n",
    "                              colbar=False)\n",
    "\n",
    "model_en_nonzero2 = run_model(top_fea = top_fea_nonzero, \n",
    "                              qcd_data_ml = qcd_data,\n",
    "                              clf = clf_EN, \n",
    "                              key = \"ptsdpm_wo_NonCpGsXY\",\n",
    "                              title= \"Current PTSD (ElasticNet-nonzero)-\\nwithout NonCpG and XY probes\",\n",
    "                              ax=ax2,\n",
    "                              yax=False)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AUC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import svm\n",
    "\n",
    "def get_auc(imp_data, ptsd_labels, classifier, model,\n",
    "            name = False, ax = False):\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    #restore default settings\n",
    "    import matplotlib as mpl\n",
    "#     mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "#     inline_rc = dict(mpl.rcParams)\n",
    "#     mpl.rcParams.update(inline_rc)\n",
    "    \n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    print(\"Classifier :\", classifier)\n",
    "    print(\"Dimension:\", imp_data.shape)\n",
    "    print(\"Dataset :\", name)\n",
    "    \n",
    "    # Run classifier with cross-validation and plot ROC curves\n",
    "    cv = StratifiedKFold(n_splits=10)\n",
    "    \n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "    # fig settings\n",
    "    if not ax:\n",
    "        print(\"here .......\")\n",
    "        fig, ax = plt.subplots(dpi=300)\n",
    "        fig.set_figheight(1.7)\n",
    "        fig.set_figwidth(2.1)\n",
    "    else:\n",
    "        print(\"Here +++++++++\")\n",
    "    \n",
    "#     SMALL_SIZE = 8\n",
    "#     MEDIUM_SIZE = 10\n",
    "#     BIGGER_SIZE = 12\n",
    "\n",
    "#     plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "#     plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "#     plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "#     plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "#     plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "#     plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "#     plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "    \n",
    "    for i, (train, test) in enumerate(cv.split(imp_data, ptsd_labels)):\n",
    "        classifier_copy = deepcopy(classifier)\n",
    "        classifier_copy.fit(imp_data[train], ptsd_labels[train])\n",
    "        viz = plot_roc_curve(classifier_copy, imp_data[test], ptsd_labels[test],\n",
    "                             name='ROC fold {}'.format(i),\n",
    "                            alpha=0.8, lw=.6, ax=ax)\n",
    "        interp_tpr = np.interp(mean_fpr, viz.fpr, viz.tpr)\n",
    "        interp_tpr[0] = 0.0\n",
    "        tprs.append(interp_tpr)\n",
    "        aucs.append(viz.roc_auc)\n",
    "\n",
    "    ax.plot([0, 1], [0, 1], linestyle='--', lw=.8, color='r',\n",
    "            label='Chance', alpha=1)\n",
    "\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "    ax.plot(mean_fpr, mean_tpr, color='b',\n",
    "            label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "            lw=.8, alpha=.8)\n",
    "\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    ax.fill_between(mean_fpr, tprs_lower, tprs_upper, \n",
    "                    color='grey', alpha=.2,\n",
    "                    label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "    # if no name passed as an argument for title\n",
    "    if not name:\n",
    "        ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05],\n",
    "               title= model)\n",
    "    else:\n",
    "        ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05],\n",
    "               title=\"ROC: \"+ \n",
    "               name+ \" (\"+ model + \")\")\n",
    "        \n",
    "    # legend, axis and ticks size    \n",
    "    ax.legend(loc=\"lower right\", prop={'size': 4})\n",
    "\n",
    "    # ax.title.set_size(7)\n",
    "    # ax.xaxis.label.set_size(5)\n",
    "    # ax.yaxis.label.set_size(5)\n",
    "    # ax.tick_params(axis='both', which='minor', labelsize=4)\n",
    "    \n",
    "    # ax.xticks.label.set_size(4)\n",
    "    # ax.yticks.label.set_size(4)\n",
    "    # plt.xticks(fontsize=4)\n",
    "    # plt.yticks(fontsize=4)\n",
    "\n",
    "    if not ax:\n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_fea.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(qcd_data['ptsdpm_wo_NonCpGs'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clfs = [clf_rf, clf_lso, clf_EN]\n",
    "# models = [ \"Random Forest\", \"Lasso\", \"Elastic Net\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get roc for all models for all data (train + test)\n",
    "# We should not use test data to tune the model to avoid information leakage\n",
    "\n",
    "for key in top_fea.keys(): # loop over keys\n",
    "    p_labels = qcd_data[key][1]\n",
    "    data = top_fea[key][0].values\n",
    "\n",
    "    # models\n",
    "    clfs = [clf_rf, clf_lso, clf_EN]\n",
    "    models = [ \"Random Forest\", \"Lasso\", \"Elastic Net\"]\n",
    "\n",
    "    # using all models and top features\n",
    "    for j in range(len(clfs)):\n",
    "            get_auc(imp_data=data, ptsd_labels= p_labels, \n",
    "                    name = \"\\nCurrent PTSD -\" + key,\n",
    "                    classifier=clfs[j],\n",
    "                    model = models[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ISTSS - AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_labels_istss = qcd_data['ptsdpm_wo_NonCpGsXY'][1]\n",
    "data_istss = top_fea['ptsdpm_wo_NonCpGsXY'][0].values\n",
    "\n",
    "fig, ax1 = plt.subplots(1, 1, dpi=300) # axes for two figures\n",
    "fig.set_figheight(2)\n",
    "fig.set_figwidth(2.5)\n",
    "\n",
    "get_auc(imp_data=data_istss, \n",
    "        ptsd_labels= p_labels_istss,       \n",
    "        name = \"\\n\", \n",
    "        classifier=clf_EN,\n",
    "        model = \"ElasticNet\",\n",
    "        ax=ax1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------Test\n",
    "# get_auc(imp_data=data, ptsd_labels= p_labels, \n",
    "#         name = \"\\nCurrent PTSD -\" + 'ptsdpm_wo_NonCpGs', \n",
    "#         classifier=clfs[0],\n",
    "#         model = models[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check roc for top features with nonzero coefficient\n",
    "for key in top_fea_nonzero.keys(): # loop over keys\n",
    "    p_labels = qcd_data[key][1]\n",
    "    data = top_fea_nonzero[key][0].values\n",
    "\n",
    "    # models\n",
    "    clfs = [clf_rf, clf_lso, clf_EN]\n",
    "    models = [ \"Random forest\", \"Lasso\", \"ElasticNet\"]\n",
    "\n",
    "    # using all models and top features\n",
    "    for j in range(len(clfs)):\n",
    "            get_auc(imp_data=data, ptsd_labels= p_labels, \n",
    "                    name = \"\\nCurrent PTSD nonzero -\" + key,\n",
    "                    classifier=clfs[j],\n",
    "                    model = models[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC without Trauma and Childhood mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_wo_pheno = top_fea['ptsdpm_wo_NonCpGsXY'][0].copy()\n",
    "top_wo_pheno = top_wo_pheno.drop([\"Traumanum\", \"Childhood_Mt\"], axis=1)\n",
    "top_wo_pheno "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ISTSS accuracy without childhood trauma and cumulative trauma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_wo_pheno_istss = {\"ptsdpm_wo_NonCpGsXY\": (top_wo_pheno, \n",
    "                                               top_fea['ptsdpm_wo_NonCpGsXY'][1].copy())\n",
    "                      }\n",
    "fig, ax3 = plt.subplots(1, 1, dpi=300)\n",
    "fig.set_figheight(2)\n",
    "fig.set_figwidth(2.5)\n",
    "elasticnet_istss_wo_exp = run_model(top_fea = top_wo_pheno_istss, \n",
    "                                   qcd_data_ml = qcd_data,\n",
    "                                   clf = clf_EN, \n",
    "                                   key = \"ptsdpm_wo_NonCpGsXY\",\n",
    "                                   title= \"Confusion matrix (ElasticNet) \\n without exposure variables\",\n",
    "                                   ax = ax3)\n",
    "ax3.set_xticklabels([\"No PTSD\", \"PTSD\"])\n",
    "ax3.set_yticklabels([\"No PTSD\", \"PTSD\"])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get weights of CpGs from the model which was run without exposure variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# feature importance - coefficients\n",
    "non_cpgsXY_imp_wo_exp = get_feature_importance(modl=elasticnet_istss_wo_exp, coef = True) \n",
    "\n",
    "importance_dfs_en_wo_exp = make_df(fea_importance=[non_cpgsXY_imp_wo_exp],\n",
    "                            top_features=top_wo_pheno_istss )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_dfs_en_wo_exp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_dfs_en_wo_exp = arrange_df(df = importance_dfs_en_wo_exp[0])\n",
    "importance_dfs_en_wo_exp\n",
    "importance_dfs_en_wo_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_dfs_en_wo_exp.to_csv(\"G:/PGC ML/Combined Data/2022-03-30_15-07-11/Important_features_wo_non_CpGsXY_EN_WO_Exposure_Vars_selected_wd_EN_l1_r_0.1.csv\",\n",
    "                                   index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (top_wo_pheno_istss['ptsdpm_wo_NonCpGsXY'][1] == qcd_data['ptsdpm_wo_NonCpGsXY'][1]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_labels_istss = qcd_data['ptsdpm_wo_NonCpGsXY'][1]\n",
    "data_istss = top_wo_pheno.values.copy()\n",
    "get_auc(imp_data=data_istss, \n",
    "        ptsd_labels= p_labels_istss,       \n",
    "        name = \"\\n\", \n",
    "        classifier=clf_EN,\n",
    "        model = \"ElasticNet, without exposure variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_wo_pheno = top_wo_pheno.values\n",
    "get_auc(imp_data=top_wo_pheno, ptsd_labels= p_labels, \n",
    "        name = \"\\nCurrent PTSD -\" + 'ptsdpm_wo_NonCpGs', \n",
    "        classifier=clfs[0],\n",
    "        model = models[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_auc(imp_data=top_wo_pheno, ptsd_labels= p_labels, \n",
    "        name = \"\\nCurrent PTSD -\" + 'ptsdpm_wo_NonCpGs', \n",
    "        classifier=clfs[1],\n",
    "        model = models[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_auc(imp_data=top_wo_pheno, ptsd_labels= p_labels, \n",
    "        name = \"\\nCurrent PTSD -\" + 'ptsdpm_wo_NonCpGs', \n",
    "        classifier=clfs[2],\n",
    "        model = models[2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots for manuscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Now run the model for features with nonzero coefficients\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, width_ratios=[1,1,1.25], dpi=300) # axes for two figures\n",
    "fig.set_figheight(2.5)\n",
    "fig.set_figwidth(8)\n",
    "en = run_model(top_fea = top_fea, \n",
    "                qcd_data_ml = qcd_data,\n",
    "                clf = clf_EN, \n",
    "                key = \"ptsdpm_wo_NonCpGsXY\",\n",
    "                title= \"Elastic Net\",\n",
    "                ax=ax1,\n",
    "                colbar=False)\n",
    "\n",
    "# ax1.set_xticklabels([\"No PTSD\", \"PTSD\"])\n",
    "# ax1.set_yticklabels([\"No PTSD\", \"PTSD\"])\n",
    "\n",
    "lasso = run_model(top_fea = top_fea, \n",
    "qcd_data_ml = qcd_data,\n",
    "clf = clf_lso, \n",
    "key = \"ptsdpm_wo_NonCpGsXY\",\n",
    "title= \"Lasso\",\n",
    "ax=ax2,\n",
    "yax=False,\n",
    "\n",
    "colbar=False)\n",
    "\n",
    "rf = run_model(top_fea = top_fea, \n",
    "                qcd_data_ml = qcd_data,\n",
    "                clf = clf_rf, \n",
    "                key = \"ptsdpm_wo_NonCpGsXY\",\n",
    "                title= \"Random Forest\",\n",
    "                ax=ax3,\n",
    "                yax=False\n",
    "                )\n",
    "\n",
    "for x in [ax1, ax2, ax3]:\n",
    "    if x ==ax1:\n",
    "        x.set_yticklabels([\"No PTSD\", \"PTSD\"])\n",
    "    if x in [ax2, ax3]:\n",
    "        x.set_yticklabels([])\n",
    "\n",
    "    x.set_xticklabels([\"No PTSD\", \"PTSD\"])\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC for manuscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot AUC for manuscript\n",
    "p_labels = qcd_data['ptsdpm_wo_NonCpGsXY'][1]\n",
    "data = top_fea['ptsdpm_wo_NonCpGsXY'][0].values\n",
    "\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, dpi=300) # axes for three figures\n",
    "fig.set_figheight(2.7)\n",
    "fig.set_figwidth(7)\n",
    "    \n",
    "# Plot elastic net, lasso and random forest in order\n",
    "get_auc(imp_data=data, \n",
    "        ptsd_labels= p_labels, \n",
    "        classifier=clfs[2],\n",
    "        model = models[2],\n",
    "        ax = ax1)\n",
    "\n",
    "get_auc(imp_data=data, \n",
    "        ptsd_labels= p_labels, \n",
    "        classifier=clfs[1],\n",
    "        model = models[1],\n",
    "        ax = ax2)\n",
    "\n",
    "get_auc(imp_data=data, \n",
    "        ptsd_labels= p_labels, \n",
    "        classifier=clfs[0],\n",
    "        model = models[0],\n",
    "        ax = ax3)\n",
    "\n",
    "for x in [ax1, ax2, ax3]:\n",
    "    if x in [ax2, ax3]:\n",
    "        x.set_yticklabels([])\n",
    "        x.set(ylabel=None)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Both confusion matrix and AUC together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot AUC for manuscript\n",
    "p_labels = qcd_data['ptsdpm_wo_NonCpGsXY'][1]\n",
    "data = top_fea['ptsdpm_wo_NonCpGsXY'][0].values\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, width_ratios=[1,1,1.25], dpi=300) # axes for two figures\n",
    "ax1, ax2, ax3, ax4, ax5, ax6 = axes.flatten()\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(8)\n",
    "en = run_model(top_fea = top_fea, \n",
    "                qcd_data_ml = qcd_data,\n",
    "                clf = clf_EN, \n",
    "                key = \"ptsdpm_wo_NonCpGsXY\",\n",
    "                title= \"Elastic Net\",\n",
    "                plot_label= 'A',\n",
    "                ax=ax1,\n",
    "                colbar=False)\n",
    "\n",
    "# ax1.set_xticklabels([\"No PTSD\", \"PTSD\"])\n",
    "# ax1.set_yticklabels([\"No PTSD\", \"PTSD\"])\n",
    "\n",
    "lasso = run_model(top_fea = top_fea, \n",
    "                  qcd_data_ml = qcd_data,\n",
    "                  clf = clf_lso, \n",
    "                  key = \"ptsdpm_wo_NonCpGsXY\",\n",
    "                  plot_label='B',\n",
    "                  title= \"Lasso\",\n",
    "                  ax=ax2,\n",
    "                  yax=False,\n",
    "                 colbar=False)\n",
    "\n",
    "rf = run_model(top_fea = top_fea, \n",
    "                qcd_data_ml = qcd_data,\n",
    "                clf = clf_rf, \n",
    "                key = \"ptsdpm_wo_NonCpGsXY\",\n",
    "                title= \"Random Forest\",\n",
    "                plot_label='C',\n",
    "                ax=ax3,\n",
    "                yax=False\n",
    "                )\n",
    "\n",
    "for x in [ax1, ax2, ax3]:\n",
    "    if x ==ax1:\n",
    "        x.set_yticklabels([\"No PTSD\", \"PTSD\"])\n",
    "    if x in [ax2, ax3]:\n",
    "        x.set_yticklabels([])\n",
    "\n",
    "    x.set_xticklabels([\"No PTSD\", \"PTSD\"])\n",
    "\n",
    "\n",
    "# fig, (ax1, ax2, ax3) = plt.subplots(1, 3, dpi=300) # axes for three figures\n",
    "# fig.set_figheight(2.8)\n",
    "# fig.set_figwidth(8)\n",
    "    \n",
    "get_auc(imp_data=data, \n",
    "        ptsd_labels= p_labels, \n",
    "        classifier=clf_EN,\n",
    "        model = '',\n",
    "        ax = ax4)\n",
    "\n",
    "get_auc(imp_data=data, \n",
    "        ptsd_labels= p_labels, \n",
    "        classifier=clf_lso,\n",
    "        model = '',\n",
    "        ax = ax5)\n",
    "\n",
    "get_auc(imp_data=data, \n",
    "        ptsd_labels= p_labels, \n",
    "        classifier=clf_rf,\n",
    "        model = '',\n",
    "        ax = ax6)\n",
    "\n",
    "for x in [ax5, ax6]:\n",
    "    x.set_yticklabels([])\n",
    "    x.set(ylabel=None)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy and AUC for Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot AUC for manuscript\n",
    "p_labels = qcd_data['ptsdpm_wo_NonCpGsXY'][1]\n",
    "data = top_fea['ptsdpm_wo_NonCpGsXY'][0].values\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, width_ratios=[1.2, 1], dpi=300) # axes for two figures\n",
    "ax1, ax2 = axes.flatten()\n",
    "fig.set_figheight(2.2)\n",
    "fig.set_figwidth(5)\n",
    "en = run_model(top_fea = top_fea, \n",
    "                qcd_data_ml = qcd_data,\n",
    "                clf = clf_EN, \n",
    "                key = \"ptsdpm_wo_NonCpGsXY\",\n",
    "                title= \"Confusion matrix: Elastic Net\",\n",
    "                ax=ax1,\n",
    "                colbar=True)\n",
    "\n",
    "ax1.set_xticklabels([\"No PTSD\", \"PTSD\"])\n",
    "ax1.set_yticklabels([\"No PTSD\", \"PTSD\"])\n",
    "\n",
    "\n",
    "    \n",
    "get_auc(imp_data=data, \n",
    "        ptsd_labels= p_labels, \n",
    "        classifier=clf_EN,\n",
    "        model = 'ROC: Elastic Net',\n",
    "        ax = ax2)\n",
    "\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy and AUC for Model 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_wo_pheno_istss = {\"ptsdpm_wo_NonCpGsXY\": (top_wo_pheno, \n",
    "#                                                top_fea['ptsdpm_wo_NonCpGsXY'][1].copy())\n",
    "#                       }\n",
    "\n",
    "# p_labels_istss = qcd_data['ptsdpm_wo_NonCpGsXY'][1]\n",
    "\n",
    "data_istss = top_wo_pheno.values.copy()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, width_ratios=[1.2, 1], dpi=300) # axes for two figures\n",
    "ax1, ax2 = axes.flatten()\n",
    "fig.set_figheight(2.2)\n",
    "fig.set_figwidth(5)\n",
    "en = run_model(top_fea = top_wo_pheno_istss, \n",
    "                qcd_data_ml = qcd_data,\n",
    "                clf = clf_EN, \n",
    "                key = \"ptsdpm_wo_NonCpGsXY\",\n",
    "                title= \"Confusion matrix: Elastic Net\",\n",
    "                ax=ax1,\n",
    "                colbar=True)\n",
    "\n",
    "ax1.set_xticklabels([\"No PTSD\", \"PTSD\"])\n",
    "ax1.set_yticklabels([\"No PTSD\", \"PTSD\"])\n",
    "\n",
    "\n",
    "    \n",
    "get_auc(imp_data=data_istss, \n",
    "        ptsd_labels= p_labels_istss, \n",
    "        classifier=clf_EN,\n",
    "        model = 'ROC: Elastic Net',\n",
    "        ax = ax2)\n",
    "\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_auc(imp_data=data, ptsd_labels= p_labels, \n",
    "        classifier=clfs[0],\n",
    "        model = models[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As we have trained the models on PTSDpm, lets use them to predict lifetime ptsd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qcd_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptsd_life_k = ['ptsdlife_wo_NonCpGs', 'ptsdlife_wo_NonCpGsXY']\n",
    "ptsd_life = {k:qcd_data[k] for k in ptsd_life_k if k in ptsd_life_k}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptsd_life.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptsd_life['ptsdlife_wo_NonCpGs'][0].iloc[:, 0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qcd_data[\"ptsdlife_wo_NonCpGs\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_indx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train on current PTSD and test on lifetime PTSD\n",
    "def run_model_lifetime(important_fea, qcd_data, clf, key, \n",
    "                        life_key, imp_indx, title, \n",
    "                       random = True, percent = None):\n",
    "    \n",
    "    # Training on current PTSD\n",
    "    print(\"Training on :\", key)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(qcd_data[key][0], \n",
    "                                                        qcd_data[key][1],\n",
    "                                                        test_size = 0.25,\n",
    "                                                        random_state = 0,\n",
    "                                                        stratify=qcd_data[key][1])\n",
    "    \n",
    "    # Samples used in training\n",
    "    train_s = X_train['Basename']\n",
    "\n",
    "    # Remove sample identifier\n",
    "    X_train, X_test = [x.loc[:,~x.columns.str.contains(\"Basename\")] \n",
    "                   for x in [X_train, X_test]]\n",
    "    \n",
    "    # Index of significant features\n",
    "    f_indx = imp_indx\n",
    "    print(f_indx)\n",
    "    \n",
    "    # Get sifnificant features from train and test\n",
    "    features = important_fea[key][f_indx][1]\n",
    "    print(\"# of features:\", len(features))\n",
    "    X_train = X_train.loc[:, X_train.columns.isin(features)].values\n",
    "    X_test = X_test.loc[:, X_test.columns.isin(features)].values\n",
    "    \n",
    "    print(\"Dimension current ptsd, train and test:\", \n",
    "          X_train.shape,X_test.shape)\n",
    "    \n",
    "    # fit on current ptsd\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    # Now test on lifetime PTSD\n",
    "    k = life_key\n",
    "    print(\"Testing on lifetime ptsd :\", k)\n",
    "    if(random): # select samples randomly\n",
    "        print(\"Randomly selecting the samples...\")\n",
    "        X_train_l, X_test_l, y_train_l, y_test_l = train_test_split(qcd_data[k][0],\n",
    "                                                                    qcd_data[k][1],\n",
    "                                                                    test_size = 0.25,\n",
    "                                                                    random_state = 0,\n",
    "                                                                    stratify=qcd_data[k][1])\n",
    "        X_test_imp_fea = X_test_l.loc[:, X_test_l.columns.isin(features)].copy()\n",
    "        X_test_imp_fea_comb = X_test_imp_fea.copy()\n",
    "        X_test_imp_fea_comb[\"ptsdlife\"] = y_test_l\n",
    "        X_test_imp_fea_comb[\"Basename\"] = X_test_l[\"Basename\"]\n",
    "        X_test_l = X_test_imp_fea.values\n",
    "        print(\"In Training current PTSD from testset in lifetime :\",\n",
    "                    X_test_imp_fea_comb['Basename'].isin(train_s).sum())\n",
    "        \n",
    "        \n",
    "    else: # select samples not used in training\n",
    "        # Now get the samples from lifetime ptsd that \n",
    "        # are not used in train (using current ptsd)\n",
    "        print(\"Selecting the samples not overlaping with training set...\")\n",
    "        comb = qcd_data[k][0].copy()\n",
    "        comb['ptsdlife'] = qcd_data[k][1]\n",
    "        others = comb.loc[~comb['Basename'].isin(train_s)] # remove those in training\n",
    "        \n",
    "        if percent is not None:\n",
    "            print(\"Using {} % of data\".format(percent))\n",
    "            others = others.sample(frac=percent).copy()\n",
    "        \n",
    "        # make test data including important features\n",
    "        X_test_imp_fea_comb = others.loc[:, others.columns.isin(features)].copy()\n",
    "        X_test_l = X_test_imp_fea_comb.values\n",
    "        y_test_l = np.array(others['ptsdlife'])\n",
    "        \n",
    "        # make a copy to return to look at case/controls with remitted\n",
    "        X_test_imp_fea_comb['ptsdlife'] = others['ptsdlife']\n",
    "        X_test_imp_fea_comb['Basename'] = others['Basename']\n",
    "    \n",
    "    print(\"Dimension lifetime ptsd, test:\", \n",
    "          X_test_l.shape)\n",
    "    \n",
    "    pred = clf.predict(X_test_l)\n",
    "    print('Classification accuracy using ptsdpm model: {:.3f}\\n',\n",
    "          classification_report(y_test_l, pred))\n",
    "    \n",
    "    build_confusion_matrix(predictions = pred,\n",
    "                           ytest=y_test_l,\n",
    "                           labels=[0,1], \n",
    "                           title = title)\n",
    "    \n",
    "    return X_test_imp_fea_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_indx[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_fea.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting lifetime PTSD using the model trained on current PTSD\n",
    "ptsdlife_testset = dict()\n",
    "for i, val in enumerate(ptsd_life_k):\n",
    "    for j in range(len(clfs)):\n",
    "        title = \"\\nLifetime PTSD (\" + models[j] +  \")-\" + val \n",
    "        out = run_model_lifetime(important_fea=important_fea,\n",
    "                       qcd_data= qcd_data, \n",
    "                       clf = clfs[j], key = keys[i], \n",
    "                       life_key=ptsd_life_k[i], imp_indx=fea_indx[i],\n",
    "                       title = title)\n",
    "        ptsdlife_testset[keys[i]] = out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test lifetime PTSD with the samples not selected randomly and not overlaping with Current PTSD test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting lifetime PTSD using the model trained on current PTSD\n",
    "# using the samples not used in training and without drawing\n",
    "# the samples at random\n",
    "ptsdlife_testset_wo_rand = dict()\n",
    "for i, val in enumerate(ptsd_life_k):\n",
    "    for j in range(len(clfs)):\n",
    "        title = \"\\nLifetime PTSD (\" + models[j] +  \")-\" + val \n",
    "        out_wo_rand = run_model_lifetime(important_fea=important_fea,\n",
    "                       qcd_data= qcd_data, \n",
    "                       clf = clfs[j], key = keys[i], \n",
    "                       life_key=ptsd_life_k[i], imp_indx=fea_indx[i],\n",
    "                       title = title, random=False)\n",
    "        ptsdlife_testset_wo_rand[keys[i]] = out_wo_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptsdlife_testset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptsdlife_testset['ptsdpm_wo_NonCpGs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many of the samples are in current PTSD\n",
    "# ptsdlife_testset['ptsdpm_wo_NonCpGs']['Basename'].isin(qcd_data['ptsdpm_wo_NonCpGs'][0]['Basename']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current PTSD information from phenotype file\n",
    "pheno = pd.read_csv(\"G:/PGC ML/Pre_Processed Data/2021-11-15_21-41-53/DNHS_GTP_MRS_ArmyS_Prismo_Pheno.csv\") \n",
    "\n",
    "# Use only one from ptsdpm_wo_NonCpGs/ptsdpm_wo_NonCpGXY\n",
    "# Both have the same samples but different features\n",
    "comn_wd_ptsdpm = [pd.merge(x['ptsdpm_wo_NonCpGs'], \n",
    "        pheno[[\"Ptsdpm\", \"Basename\"]], on='Basename') for x in [ptsdlife_testset, ptsdlife_testset_wo_rand]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x.shape for x in comn_wd_ptsdpm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in comn_wd_ptsdpm:\n",
    "    df['Ptsdpm'] = df['Ptsdpm'].astype('Int64')\n",
    "\n",
    "[x.shape for x in comn_wd_ptsdpm]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of remitted - ptsdpm == 0 & ptsdlife ==1\n",
    "[(((x['Ptsdpm'] == 0) & (x['ptsdlife'] == 1)).sum()) for x in comn_wd_ptsdpm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of cases and controls in lifetime PTSD testset\n",
    "count = [(x['ptsdlife'].value_counts()) for x in comn_wd_ptsdpm]\n",
    "[(x, x/x.sum()) for x in count] # percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# when percentage as input for test set \n",
    "# ptsdlife_testset_wo_rand_per = dict()\n",
    "# for i, val in enumerate(ptsd_life_k):\n",
    "#     for j in range(len(clfs)):\n",
    "#         title = \"\\nLifetime PTSD (\" + models[j] +  \")-\" + val \n",
    "#         out_wo_rand_per = run_model_lifetime(important_fea=important_fea,\n",
    "#                        qcd_data= qcd_data, \n",
    "#                        clf = clfs[j], key = keys[i], \n",
    "#                        life_key=ptsd_life_k[i], imp_indx=fea_indx[i],\n",
    "#                        title = title, random=False, percent = 0.30)\n",
    "#         ptsdlife_testset_wo_rand_per[keys[i]] = out_wo_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_indx\n",
    "keys[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptsd_life_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_wo_rand_per1 = run_model_lifetime_test(important_fea=important_fea,\n",
    "#                        qcd_data= qcd_data, \n",
    "#                        clf = clfs[2], key = keys[1], \n",
    "#                        life_key=ptsd_life_k[1], imp_indx=fea_indx[1],\n",
    "#                        title = title, random=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_wo_rand_per1 = run_model_lifetime_test(important_fea=important_fea,\n",
    "#                        qcd_data= qcd_data, \n",
    "#                        clf = clfs[2], key = keys[1], \n",
    "#                        life_key=ptsd_life_k[1], imp_indx=fea_indx[1],\n",
    "#                        title = title, random=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets save the lifetime test dataset with important features \n",
    "# to generate methylation risk score\n",
    "\n",
    "path = \"G:/PGC ML/Combined Data/2022-03-30_15-07-11/\"\n",
    "for i, k in enumerate(ptsdlife_keys):\n",
    "    print(\"Testing on lifetime ptsd :\", k)\n",
    "    X_train_l, X_test_l, y_train_l, y_test_l = train_test_split(qcd_data[k][0], \n",
    "                                                                qcd_data[k][1],\n",
    "                                                                test_size = 0.25,\n",
    "                                                                random_state = 0,\n",
    "                                                           stratify=qcd_data[k][1])\n",
    "\n",
    "    ptsd_life_test = X_test_l.loc[:, X_test_l.columns.isin(important_fea[keys[i]][fea_indx[i]][1])]\n",
    "\n",
    "    # all should be true\n",
    "    print(\"All matching :\",\n",
    "         (ptsd_life_test.columns == important_fea[keys[i]][fea_indx[i]][1]).all())\n",
    "\n",
    "    \n",
    "    ptsdlife_test_imp = ptsd_life_test.copy()\n",
    "    ptsdlife_test_imp['PtsdLife'] = y_test_l\n",
    "    ptsdlife_test_imp['Basename'] = X_test_l['Basename']\n",
    "    \n",
    "    \n",
    "    #save\n",
    "    ptsdlife_test_imp.to_csv(path + \"ElasticNet_\"+ k + \"testset_important_features.csv\", index=False)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the accuracy without childhood maltreatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_fea.keys(), top_fea['ptsdpm_wo_NonCpGs'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop childhood maltreatment\n",
    "top_wo_cm = [dict({k:(top_fea[k][0].drop(columns=['Childhood_Mt']).copy(),\n",
    "                       qcd_data[k][1])}) for k in top_fea.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape after removing childhood maltreatment\n",
    "for i, k in enumerate(keys):\n",
    "    print(f\"# of features in {k} df: {top_wo_cm[i][k][0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model top features without childhood mt\n",
    "en_wo_cm = run_model(top_wo_cm[0], qcd_data, clf_EN, keys[0],\n",
    "         title = f\"\\nCurrent PTSD without CM (ElasticNet)-{keys[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_wo_cm1 = run_model(top_wo_cm[1], qcd_data, clf_EN, keys[1],\n",
    "         title = f\"\\nCurrent PTSD without CM (ElasticNet)-{keys[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest\n",
    "# rf_wo_cm = run_model(top_wo_cm[0], qcd_data, clf_rf, keys[0],\n",
    "#          title = f\"\\nCurrent PTSD without CM (Random forest)-{keys[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_wo_cm1 = run_model(top_wo_cm[1], qcd_data, clf_rf, keys[1],\n",
    "#          title = f\"\\nCurrent PTSD without CM (Random forest)-{keys[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_wo_cm_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get feature importance\n",
    "# rf_wo_cm_imp = [x.steps[1][1].feature_importances_ for x in [rf_wo_cm, rf_wo_cm1]]\n",
    "# print(f\"# of feature imp dfs: {len(rf_wo_cm_imp)}\")\n",
    "# print(f\"# of features in first df: {len(rf_wo_cm_imp[0])}\")\n",
    "# print(f\"# of features in second df: {len(rf_wo_cm_imp[1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_importance_df(imp_df, fea):\n",
    "    imp_df_wo_cm = pd.DataFrame(imp_df, fea.columns) \n",
    "    imp_df_wo_cm.reset_index(inplace=True)\n",
    "    imp_df_wo_cm.columns = ['Feature', \"Importance\"]\n",
    "    imp_df_wo_cm.sort_values(by=['Importance'], inplace=True)\n",
    "    return(imp_df_wo_cm)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call function to create dfs\n",
    "# imp_df_wo_cm = [create_importance_df(imp_df=rf_wo_cm_imp[i],\n",
    "#                                      fea=top_wo_cm[i][keys[i]][0]) for i in range(len(rf_wo_cm_imp))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [x.shape for x in imp_df_wo_cm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [x.head() for x in imp_df_wo_cm]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we calculate methylation risk scores based on the weights (feature importance). The methylation risk score is the weighted sum of the important freatures for each individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_dfs_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now divide the data into train and test and\n",
    "# get the top features and scale the traumanum and childhood cols\n",
    "# use only test set to calulate methylation risk scores\n",
    "def get_top_features_testset(key, imp_df):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(qcd_data[key][0], \n",
    "                                                        qcd_data[key][1],\n",
    "                                                        test_size = 0.25,\n",
    "                                                        random_state = 0,\n",
    "                                                        stratify=qcd_data[key][1])\n",
    "    \n",
    "    # Pull important features. We need only test data\n",
    "    top_fea_train = X_train.loc[:, X_train.columns.isin(top_fea[key][0].columns)].copy()\n",
    "    top_fea_test = X_test.loc[:, X_test.columns.isin(top_fea[key][0].columns)].copy()\n",
    "    \n",
    "    print(f\"X_test dim: {top_fea_test.shape}\")\n",
    "    print(f\"# of test labels: {len(y_test)}\")\n",
    "#     print(top_fea_test.head())\n",
    "    \n",
    "    # sort the colums based on the order in feature importance df\n",
    "    top_fea_train = top_fea_train[imp_df['Feature']].copy()\n",
    "    top_fea_test = top_fea_test[imp_df['Feature']].copy()\n",
    "    \n",
    "    # after sorting the columns, index is reset. So lets reindex it to original\n",
    "    top_fea_test = top_fea_test.reindex(X_test.index) \n",
    "    ids = X_test['Basename'].copy()\n",
    "    \n",
    "    # check the order is same\n",
    "    print(\"Training set in order :\", (top_fea_train.columns == imp_df[\"Feature\"]).all())\n",
    "    print(\"Test set in order :\", (top_fea_test.columns == imp_df[\"Feature\"]).all())\n",
    "    return(top_fea_test, y_test, ids)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_fea_test1, top_fea_test2 = [get_top_features_testset(key = keys[i], \n",
    "                                   imp_df = importance_dfs_en[i]) for i in range(len(keys))]\n",
    "print(f\"dim first df : {top_fea_test1[0].shape}, # test labels: {len(top_fea_test1[1])}\")\n",
    "print(f\"dim second df : {top_fea_test2[0].shape}, # test labels: {len(top_fea_test2[1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert feature column to index\n",
    "importance_dfs_new = [x.set_index('Feature') for x in importance_dfs_en]\n",
    "[x.head() for x in importance_dfs_new ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now scale two columns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scl_cols = [\"Traumanum\", \"Childhood_Mt\"]\n",
    "\n",
    "def scale_data(df, cols):\n",
    "    scaler = MinMaxScaler()\n",
    "    indx = df.index\n",
    "    scaled = scaler.fit_transform(df[cols])\n",
    "    scaled = pd.DataFrame(scaled, indx, columns=cols)\n",
    "    return(scaled)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call scale function on the required columns of test data\n",
    "scaled_test = [scale_data(df = x, \n",
    "                          cols=scl_cols) for x in [top_fea_test1[0], \n",
    "                                                   top_fea_test2[0]]]\n",
    "scaled_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index to replace the columns with scaled\n",
    "# [x.reset_index(drop=True, inplace=True) for x in [top_fea_test1[0],\n",
    "#                                                  top_fea_test2[0]]]\n",
    "top_fea_test1[0][scl_cols] = scaled_test[0][scl_cols]\n",
    "top_fea_test2[0][scl_cols] = scaled_test[1][scl_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_fea_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get risk scores for both train and test data\n",
    "# get weighted sum\n",
    "# top_fea_train[\"risk_score\"] = top_fea_train.dot(importance_df_new['Importance'])\n",
    "top_fea_test1[0][\"risk_score\"] = top_fea_test1[0].dot(importance_dfs_new[0]['Importance'])\n",
    "top_fea_test2[0][\"risk_score\"] = top_fea_test2[0].dot(importance_dfs_new[1]['Importance'])\n",
    "top_fea_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_fea_test2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make copy\n",
    "rsk_scores_test =  [top_fea_test1[0].copy(), top_fea_test2[0].copy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in rsk_scores_test:\n",
    "    print(f\"dim : {x.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_fea_test1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_fea_test1[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding PTSD labels. We also need to reset the index of \n",
    "# basenames to add the ids to risk_scores df\n",
    "rsk_scores_test[0][\"ptsdpm\"] = top_fea_test1[1]\n",
    "# top_fea_test1[2].reset_index(drop=True, inplace = True)\n",
    "rsk_scores_test[0][\"Basename\"] = top_fea_test1[2]\n",
    "\n",
    "# top_fea_test2[2].reset_index(drop=True, inplace = True)\n",
    "rsk_scores_test[1][\"ptsdpm\"] = top_fea_test2[1]\n",
    "rsk_scores_test[1][\"Basename\"] = top_fea_test2[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print head\n",
    "print(f\"First df : {rsk_scores_test[0].shape}\")\n",
    "print(f\"Second df : {rsk_scores_test[1].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsk_scores_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we have all the important features before writing the data\n",
    "rsk_scores_test[0].columns.isin(top_fea['ptsdpm_wo_NonCpGs'][0].columns).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsk_scores_test[1].columns.isin(top_fea['ptsdpm_wo_NonCpGsXY'][0].columns).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save risk scores on test data 2021-10-02_23-12-43\n",
    "# rsk_scores_train.to_csv(\"G:/PGC ML/Combined Data/2021-11-27_19-16-35/risk scores ptsdpm training data.csv\",\n",
    "#                        index=False)\n",
    "\n",
    "writer_test = pd.ExcelWriter(path + 'Elasticnet risk scores ptsdpm test data.xlsx', \n",
    "                        engine='xlsxwriter')\n",
    "\n",
    "\n",
    "rsk_scores_test[0].to_excel(writer_test, sheet_name=\"Without NonCpG Probes\",\n",
    "                         index=False)\n",
    "rsk_scores_test[1].to_excel(writer_test, sheet_name=\"Without NonCpGXY Probes\",\n",
    "                         index=False)\n",
    "\n",
    "writer_test.save()\n",
    "\n",
    "# rsk_scores_test.to_csv(\"G:/PGC ML/Combined Data/2021-11-27_19-16-35/risk scores ptsdpm test data.csv\", \n",
    "#                       index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear model on test data using risk scores\n",
    "from sklearn.linear_model import LinearRegression\n",
    "rsk_scores = np.array(rsk_scores_test[0].iloc[:, -3:-2])\n",
    "df = rsk_scores_test[0].iloc[:, :-1]\n",
    "y_test = np.array(rsk_scores_test[0].iloc[:, -2:-1]) # ptsd as outcome\n",
    "reg = LinearRegression().fit(rsk_scores, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.score(rsk_scores, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other old code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets use updated data frame to train and test the model\n",
    "# it has a risk score column\n",
    "# create dict with df and number of features\n",
    "top_fea_wd_rs = dict({'ptsdpm_cov_adj': (top_fea_test, 301)})\n",
    "top_fea_wd_rs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key = 'ptsdpm_cov_adj'\n",
    "# run_model(top_fea = top_fea_wd_rs, \n",
    "#           qcd_data_ml = qcd_data,\n",
    "#           clf = clf_rf, key = key, \n",
    "#          title = \"current PTSD (Random forest)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc curve\n",
    "# p_labels = qcd_data[key][1]\n",
    "# data = top_fea_wd_rs[key][0].values\n",
    "# get_auc(imp_data=data, ptsd_labels= p_labels, \n",
    "#         name = \"current PTSD\", classifier = clf_rf,\n",
    "#        model = \"Random forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now using only risk scores to predict ptsd\n",
    "risk_sc = dict({\"ptsdpm_cov_adj\":(top_fea_test.iloc[:, -1:], 1)})\n",
    "risk_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using weights on training data\n",
    "top_fea_all = top_fea['ptsdpm_cov_adj'][0].copy()\n",
    "top_fea_sor_all = top_fea_all[importance_df['Feature']]\n",
    "top_fea_sor_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "all_scaled = scaler.fit_transform(top_fea_sor_all[scl_cols])\n",
    "all_scaled = pd.DataFrame(all_scaled, columns=scl_cols)\n",
    "all_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index to replace the columns with scaled \n",
    "top_fea_sor_all.reset_index(drop=True, inplace=True)\n",
    "top_fea_sor_all[scl_cols] = all_scaled[scl_cols]\n",
    "top_fea_sor_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_sc_all = top_fea_sor_all.dot(importance_df_new['Importance'])\n",
    "top_fea_sor_all['risk_score'] = risk_sc_all\n",
    "top_fea_sor_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_fea_sor_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_sc_all = dict({'ptsdpm_cov_adj':(top_fea_sor_all.iloc[:, -1:], len(risk_sc_all))})\n",
    "risk_sc_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "def get_auc_varient(imp_data, ptsd_labels, name, \n",
    "           classifier, classifier1, model):\n",
    "    import matplotlib.pyplot as plt\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    print(\"Classifier :\", classifier)\n",
    "    # Run classifier with cross-validation and plot ROC curves\n",
    "    cv = StratifiedKFold(n_splits=10)\n",
    "\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    for i, (train, test) in enumerate(cv.split(imp_data, ptsd_labels)):\n",
    "        \n",
    "        # fit model\n",
    "        classifier1.fit(imp_data[train], ptsd_labels[train])\n",
    "        \n",
    "        # get importance and calculate risk scores\n",
    "        imp_per =  classifier1.named_steps.balancedrandomforestclassifier.feature_importances_\n",
    "        risk_trn = imp_data[train].dot(imp_per)\n",
    "        risk_df_trn = pd.DataFrame(risk_trn, columns=['risk'])\n",
    "        \n",
    "        # risk scores for test using weights calculated\n",
    "        # on training data\n",
    "        risk_test = imp_data[test].dot(imp_per)\n",
    "        risk_df_test = pd.DataFrame(risk_test, columns=['risk'])\n",
    "        \n",
    "        # fit model again using only risk scores\n",
    "        classifier.fit(risk_df_trn, ptsd_labels[train])\n",
    "\n",
    "        \n",
    "        viz = plot_roc_curve(classifier, risk_df_test, ptsd_labels[test],\n",
    "                             name='ROC fold {}'.format(i),\n",
    "                             alpha=0.3, lw=1, ax=ax)\n",
    "        interp_tpr = np.interp(mean_fpr, viz.fpr, viz.tpr)\n",
    "        interp_tpr[0] = 0.0\n",
    "        tprs.append(interp_tpr)\n",
    "        aucs.append(viz.roc_auc)\n",
    "\n",
    "    ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "            label='Chance', alpha=.8)\n",
    "\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "    ax.plot(mean_fpr, mean_tpr, color='b',\n",
    "            label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "            lw=2, alpha=.8)\n",
    "\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    ax.fill_between(mean_fpr, tprs_lower, tprs_upper, \n",
    "                    color='grey', alpha=.2,\n",
    "                    label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "    ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05],\n",
    "           title=\"Receiver operating characteristic: \"+ \n",
    "           name+ \" (\"+ model + \")\" )\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model(top_fea = risk_sc_all, \n",
    "          qcd_data_ml = qcd_data,\n",
    "          clf = clf_rf, key = key, \n",
    "         title = \"current PTSD (Random forest)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# p_labels = qcd_data[key][1]\n",
    "# data = top_fea[key][0].values\n",
    "# get_auc_varient(imp_data=data, ptsd_labels= p_labels, \n",
    "#                 name = \"current PTSD\", \n",
    "#                 classifier = clf_rf,\n",
    "#                 classifier1 = clf_rf,\n",
    "#                 model = \"Random forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model(top_fea = risk_sc_all, \n",
    "          qcd_data_ml = qcd_data,\n",
    "          clf = clf_lso, key = key, \n",
    "         title = \"current PTSD (Lasso)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = top_fea[key][0].values\n",
    "# get_auc_varient(imp_data=data, ptsd_labels= p_labels, \n",
    "#                 name = \"current PTSD\", \n",
    "#                 classifier = clf_lso,\n",
    "#                 classifier1= clf_rf,\n",
    "#                 model = \"Lasso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model(top_fea = risk_sc_all, \n",
    "          qcd_data_ml = qcd_data,\n",
    "          clf = clf_EN, key = key, \n",
    "         title = \"current PTSD (ElasticNet)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using only risk scores to predict\n",
    "p_labels = qcd_data[key][1]\n",
    "data = risk_sc_all[key][0].values\n",
    "for j in range(len(clfs)):\n",
    "        get_auc(imp_data=data, ptsd_labels= p_labels, \n",
    "                name = \"current PTSD\", classifier=clfs[j],\n",
    "                model = models[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = top_fea[key][0].values\n",
    "# get_auc_varient(imp_data=data, ptsd_labels= p_labels, \n",
    "#         name = \"current PTSD\", \n",
    "#         classifier = clf_EN,\n",
    "#         classifier1= clf_rf,\n",
    "#         model = \"ElasticNet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imp_data = top_fea[key][0].values\n",
    "# ptsd_labels = qcd_data[key][1]\n",
    "# cv = StratifiedKFold(n_splits=2)\n",
    "# for i, (train, test) in enumerate(cv.split(imp_data, ptsd_labels)):\n",
    "#         clf_rf.fit(imp_data[train], ptsd_labels[train])\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imp_per =  clf_rf.named_steps.balancedrandomforestclassifier.feature_importances_\n",
    "# risk = imp_data[train].dot(imp_per)\n",
    "# risk_df = pd.DataFrame(risk, columns=['risk'])\n",
    "\n",
    "# clf_rf.fit(risk_df, ptsd_labels[train])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parms = joblib.load(\"G:/PGC ML/Model tuning/2021-10-20_15-35-10/Finetuned_models.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_prms = tuned_parms['ptsdpm_cov_adj']['clf_tun'].best_params_\n",
    "best_prms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now using important features using kbest approach and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appropriate model according to feature set\n",
    "tuned_clf = make_pipeline(MinMaxScaler(),\n",
    "                BalancedRandomForestClassifier(**best_prms))\n",
    "run_model(top_fea = top_fea, \n",
    "          qcd_data_ml = qcd_data,\n",
    "          clf = tuned_clf, key = key, \n",
    "         title = \"current PTSD (Random forest)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = top_fea[key][0].values\n",
    "get_auc(imp_data=data, ptsd_labels= p_labels, \n",
    "        name = \"current PTSD\", classifier = tuned_clf,\n",
    "       model = \"Random forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
